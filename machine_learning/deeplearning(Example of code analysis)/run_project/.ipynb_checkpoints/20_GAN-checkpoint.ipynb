{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 28, 28, 1)         865281    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 212865    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n",
      "epoch:0  d_loss:0.7053  g_loss:0.6912\n",
      "epoch:1  d_loss:0.4624  g_loss:0.3282\n",
      "epoch:2  d_loss:0.5685  g_loss:0.1025\n",
      "epoch:3  d_loss:0.6585  g_loss:0.0836\n",
      "epoch:4  d_loss:0.5768  g_loss:0.1651\n",
      "epoch:5  d_loss:0.5088  g_loss:0.4210\n",
      "epoch:6  d_loss:0.4876  g_loss:0.6972\n",
      "epoch:7  d_loss:0.5092  g_loss:0.8697\n",
      "epoch:8  d_loss:0.4966  g_loss:0.8970\n",
      "epoch:9  d_loss:0.4860  g_loss:0.8720\n",
      "epoch:10  d_loss:0.4173  g_loss:0.7869\n",
      "epoch:11  d_loss:0.4385  g_loss:0.8098\n",
      "epoch:12  d_loss:0.4813  g_loss:0.8665\n",
      "epoch:13  d_loss:0.4735  g_loss:0.9191\n",
      "epoch:14  d_loss:0.5689  g_loss:0.9725\n",
      "epoch:15  d_loss:0.4707  g_loss:1.0498\n",
      "epoch:16  d_loss:0.4008  g_loss:1.0505\n",
      "epoch:17  d_loss:0.6223  g_loss:0.7720\n",
      "epoch:18  d_loss:0.5659  g_loss:0.6378\n",
      "epoch:19  d_loss:0.4575  g_loss:0.7249\n",
      "epoch:20  d_loss:0.4221  g_loss:0.8080\n",
      "epoch:21  d_loss:0.5017  g_loss:0.8385\n",
      "epoch:22  d_loss:0.5141  g_loss:0.6779\n",
      "epoch:23  d_loss:0.4558  g_loss:0.6296\n",
      "epoch:24  d_loss:0.4512  g_loss:0.6727\n",
      "epoch:25  d_loss:0.4671  g_loss:0.7299\n",
      "epoch:26  d_loss:0.5157  g_loss:0.7307\n",
      "epoch:27  d_loss:0.4791  g_loss:0.6026\n",
      "epoch:28  d_loss:0.4966  g_loss:0.5400\n",
      "epoch:29  d_loss:0.5218  g_loss:0.5520\n",
      "epoch:30  d_loss:0.4421  g_loss:0.6207\n",
      "epoch:31  d_loss:0.4793  g_loss:0.6836\n",
      "epoch:32  d_loss:0.4356  g_loss:0.5770\n",
      "epoch:33  d_loss:0.4366  g_loss:0.6165\n",
      "epoch:34  d_loss:0.3324  g_loss:0.6970\n",
      "epoch:35  d_loss:0.3674  g_loss:0.8604\n",
      "epoch:36  d_loss:0.4441  g_loss:0.5701\n",
      "epoch:37  d_loss:0.3552  g_loss:0.7422\n",
      "epoch:38  d_loss:0.3368  g_loss:0.9185\n",
      "epoch:39  d_loss:0.2328  g_loss:1.2259\n",
      "epoch:40  d_loss:0.3155  g_loss:1.2603\n",
      "epoch:41  d_loss:0.4264  g_loss:0.9288\n",
      "epoch:42  d_loss:0.3829  g_loss:0.8286\n",
      "epoch:43  d_loss:0.2395  g_loss:1.2503\n",
      "epoch:44  d_loss:0.2014  g_loss:1.5022\n",
      "epoch:45  d_loss:0.1646  g_loss:2.3479\n",
      "epoch:46  d_loss:0.3374  g_loss:1.8633\n",
      "epoch:47  d_loss:0.2597  g_loss:1.2813\n",
      "epoch:48  d_loss:0.3020  g_loss:1.3940\n",
      "epoch:49  d_loss:0.3037  g_loss:1.6298\n",
      "epoch:50  d_loss:0.3001  g_loss:1.8431\n",
      "epoch:51  d_loss:0.3822  g_loss:2.2962\n",
      "epoch:52  d_loss:0.2749  g_loss:2.2408\n",
      "epoch:53  d_loss:0.1407  g_loss:1.6925\n",
      "epoch:54  d_loss:0.1043  g_loss:1.7622\n",
      "epoch:55  d_loss:0.1071  g_loss:2.4974\n",
      "epoch:56  d_loss:0.1398  g_loss:2.4212\n",
      "epoch:57  d_loss:0.2365  g_loss:2.4429\n",
      "epoch:58  d_loss:0.2366  g_loss:2.7333\n",
      "epoch:59  d_loss:0.3781  g_loss:2.0950\n",
      "epoch:60  d_loss:0.6509  g_loss:1.9652\n",
      "epoch:61  d_loss:0.5413  g_loss:3.2046\n",
      "epoch:62  d_loss:0.8946  g_loss:2.5528\n",
      "epoch:63  d_loss:0.9153  g_loss:1.7838\n",
      "epoch:64  d_loss:0.6811  g_loss:2.2555\n",
      "epoch:65  d_loss:0.6697  g_loss:3.2222\n",
      "epoch:66  d_loss:0.3872  g_loss:3.6614\n",
      "epoch:67  d_loss:0.2137  g_loss:3.7469\n",
      "epoch:68  d_loss:0.1789  g_loss:3.7377\n",
      "epoch:69  d_loss:0.3005  g_loss:3.6988\n",
      "epoch:70  d_loss:0.4197  g_loss:2.8592\n",
      "epoch:71  d_loss:0.2529  g_loss:2.8536\n",
      "epoch:72  d_loss:0.4807  g_loss:2.2327\n",
      "epoch:73  d_loss:0.2941  g_loss:2.6862\n",
      "epoch:74  d_loss:0.6795  g_loss:1.5722\n",
      "epoch:75  d_loss:0.7438  g_loss:0.9223\n",
      "epoch:76  d_loss:0.6920  g_loss:0.8755\n",
      "epoch:77  d_loss:0.7507  g_loss:1.3772\n",
      "epoch:78  d_loss:0.7551  g_loss:1.3854\n",
      "epoch:79  d_loss:0.7213  g_loss:1.6081\n",
      "epoch:80  d_loss:0.5235  g_loss:1.8234\n",
      "epoch:81  d_loss:0.3626  g_loss:2.7553\n",
      "epoch:82  d_loss:0.2003  g_loss:3.6642\n",
      "epoch:83  d_loss:0.1364  g_loss:4.8597\n",
      "epoch:84  d_loss:0.1758  g_loss:4.0873\n",
      "epoch:85  d_loss:0.3990  g_loss:4.4096\n",
      "epoch:86  d_loss:0.3040  g_loss:5.8161\n",
      "epoch:87  d_loss:0.3961  g_loss:5.9772\n",
      "epoch:88  d_loss:0.8307  g_loss:5.0507\n",
      "epoch:89  d_loss:1.0784  g_loss:4.5800\n",
      "epoch:90  d_loss:0.6935  g_loss:5.0303\n",
      "epoch:91  d_loss:0.9624  g_loss:4.6076\n",
      "epoch:92  d_loss:1.2077  g_loss:3.4503\n",
      "epoch:93  d_loss:1.1107  g_loss:2.7046\n",
      "epoch:94  d_loss:0.9294  g_loss:1.9934\n",
      "epoch:95  d_loss:0.6819  g_loss:1.8067\n",
      "epoch:96  d_loss:0.5927  g_loss:1.8725\n",
      "epoch:97  d_loss:0.4996  g_loss:2.0867\n",
      "epoch:98  d_loss:0.4804  g_loss:1.6953\n",
      "epoch:99  d_loss:0.4809  g_loss:1.4056\n",
      "epoch:100  d_loss:0.5158  g_loss:1.3183\n",
      "epoch:101  d_loss:0.3240  g_loss:1.1362\n",
      "epoch:102  d_loss:0.3015  g_loss:1.2900\n",
      "epoch:103  d_loss:0.4150  g_loss:0.9650\n",
      "epoch:104  d_loss:0.3082  g_loss:1.0500\n",
      "epoch:105  d_loss:0.4531  g_loss:0.7947\n",
      "epoch:106  d_loss:0.4676  g_loss:0.9323\n",
      "epoch:107  d_loss:0.3472  g_loss:1.0468\n",
      "epoch:108  d_loss:0.4350  g_loss:0.9422\n",
      "epoch:109  d_loss:0.3537  g_loss:0.8887\n",
      "epoch:110  d_loss:0.3423  g_loss:0.9668\n",
      "epoch:111  d_loss:0.4398  g_loss:0.7424\n",
      "epoch:112  d_loss:0.4642  g_loss:0.8964\n",
      "epoch:113  d_loss:0.5209  g_loss:0.8880\n",
      "epoch:114  d_loss:0.5906  g_loss:0.7208\n",
      "epoch:115  d_loss:0.5126  g_loss:0.7811\n",
      "epoch:116  d_loss:0.5046  g_loss:0.6348\n",
      "epoch:117  d_loss:0.5466  g_loss:0.6054\n",
      "epoch:118  d_loss:0.6177  g_loss:0.6544\n",
      "epoch:119  d_loss:0.4390  g_loss:0.8427\n",
      "epoch:120  d_loss:0.5933  g_loss:0.7361\n",
      "epoch:121  d_loss:0.7902  g_loss:0.6842\n",
      "epoch:122  d_loss:0.8090  g_loss:0.6454\n",
      "epoch:123  d_loss:0.6777  g_loss:0.8226\n",
      "epoch:124  d_loss:0.5844  g_loss:0.7837\n",
      "epoch:125  d_loss:0.8997  g_loss:0.7831\n",
      "epoch:126  d_loss:0.7569  g_loss:0.7311\n",
      "epoch:127  d_loss:0.6814  g_loss:0.9250\n",
      "epoch:128  d_loss:0.6502  g_loss:0.9324\n",
      "epoch:129  d_loss:0.6434  g_loss:1.0180\n",
      "epoch:130  d_loss:0.6281  g_loss:1.0646\n",
      "epoch:131  d_loss:0.6659  g_loss:1.1132\n",
      "epoch:132  d_loss:0.6014  g_loss:1.1892\n",
      "epoch:133  d_loss:0.5815  g_loss:1.3533\n",
      "epoch:134  d_loss:0.5128  g_loss:1.3415\n",
      "epoch:135  d_loss:0.4831  g_loss:1.4234\n",
      "epoch:136  d_loss:0.4860  g_loss:1.6242\n",
      "epoch:137  d_loss:0.3766  g_loss:1.7693\n",
      "epoch:138  d_loss:0.3688  g_loss:1.9090\n",
      "epoch:139  d_loss:0.3347  g_loss:1.9956\n",
      "epoch:140  d_loss:0.3161  g_loss:2.1602\n",
      "epoch:141  d_loss:0.3377  g_loss:1.9320\n",
      "epoch:142  d_loss:0.3087  g_loss:2.1021\n",
      "epoch:143  d_loss:0.2240  g_loss:2.1710\n",
      "epoch:144  d_loss:0.3044  g_loss:2.2738\n",
      "epoch:145  d_loss:0.3134  g_loss:2.4622\n",
      "epoch:146  d_loss:0.2772  g_loss:3.1301\n",
      "epoch:147  d_loss:0.6261  g_loss:2.4073\n",
      "epoch:148  d_loss:0.5330  g_loss:2.4208\n",
      "epoch:149  d_loss:0.5966  g_loss:2.6329\n",
      "epoch:150  d_loss:0.4883  g_loss:3.1032\n",
      "epoch:151  d_loss:0.7424  g_loss:2.4473\n",
      "epoch:152  d_loss:0.9396  g_loss:1.6174\n",
      "epoch:153  d_loss:0.7831  g_loss:1.4626\n",
      "epoch:154  d_loss:0.6784  g_loss:1.4557\n",
      "epoch:155  d_loss:0.8026  g_loss:1.3981\n",
      "epoch:156  d_loss:0.8863  g_loss:1.5550\n",
      "epoch:157  d_loss:0.7258  g_loss:1.4690\n",
      "epoch:158  d_loss:0.8217  g_loss:1.2942\n",
      "epoch:159  d_loss:0.6718  g_loss:1.4093\n",
      "epoch:160  d_loss:0.7223  g_loss:1.3317\n",
      "epoch:161  d_loss:0.7105  g_loss:1.4078\n",
      "epoch:162  d_loss:0.6801  g_loss:1.1135\n",
      "epoch:163  d_loss:0.6494  g_loss:1.3069\n",
      "epoch:164  d_loss:0.5670  g_loss:1.2831\n",
      "epoch:165  d_loss:0.4868  g_loss:1.3566\n",
      "epoch:166  d_loss:0.5239  g_loss:1.3863\n",
      "epoch:167  d_loss:0.5132  g_loss:1.2872\n",
      "epoch:168  d_loss:0.4873  g_loss:1.2696\n",
      "epoch:169  d_loss:0.5196  g_loss:1.3153\n",
      "epoch:170  d_loss:0.4780  g_loss:1.1401\n",
      "epoch:171  d_loss:0.4810  g_loss:1.1631\n",
      "epoch:172  d_loss:0.4235  g_loss:1.3100\n",
      "epoch:173  d_loss:0.4146  g_loss:1.2478\n",
      "epoch:174  d_loss:0.4502  g_loss:1.3544\n",
      "epoch:175  d_loss:0.4148  g_loss:1.4197\n",
      "epoch:176  d_loss:0.4274  g_loss:1.4867\n",
      "epoch:177  d_loss:0.4188  g_loss:1.5476\n",
      "epoch:178  d_loss:0.3530  g_loss:1.5728\n",
      "epoch:179  d_loss:0.4056  g_loss:1.4253\n",
      "epoch:180  d_loss:0.3377  g_loss:1.3446\n",
      "epoch:181  d_loss:0.3473  g_loss:1.5422\n",
      "epoch:182  d_loss:0.3511  g_loss:1.5452\n",
      "epoch:183  d_loss:0.3139  g_loss:1.5786\n",
      "epoch:184  d_loss:0.2952  g_loss:1.4518\n",
      "epoch:185  d_loss:0.3904  g_loss:1.3377\n",
      "epoch:186  d_loss:0.3814  g_loss:1.5923\n",
      "epoch:187  d_loss:0.3773  g_loss:1.5023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:188  d_loss:0.4822  g_loss:1.3405\n",
      "epoch:189  d_loss:0.3843  g_loss:1.2944\n",
      "epoch:190  d_loss:0.3134  g_loss:1.4440\n",
      "epoch:191  d_loss:0.4693  g_loss:1.6170\n",
      "epoch:192  d_loss:0.3930  g_loss:1.5183\n",
      "epoch:193  d_loss:0.4938  g_loss:1.1978\n",
      "epoch:194  d_loss:0.4543  g_loss:1.2260\n",
      "epoch:195  d_loss:0.4334  g_loss:1.3184\n",
      "epoch:196  d_loss:0.5273  g_loss:1.3113\n",
      "epoch:197  d_loss:0.3985  g_loss:1.2179\n",
      "epoch:198  d_loss:0.5303  g_loss:1.3631\n",
      "epoch:199  d_loss:0.5652  g_loss:1.4994\n",
      "epoch:200  d_loss:0.5282  g_loss:1.4129\n",
      "epoch:201  d_loss:0.3855  g_loss:1.4418\n",
      "epoch:202  d_loss:0.6514  g_loss:1.2334\n",
      "epoch:203  d_loss:0.5023  g_loss:1.2553\n",
      "epoch:204  d_loss:0.5921  g_loss:1.1983\n",
      "epoch:205  d_loss:0.5509  g_loss:1.4127\n",
      "epoch:206  d_loss:0.5536  g_loss:1.5703\n",
      "epoch:207  d_loss:0.6602  g_loss:1.4375\n",
      "epoch:208  d_loss:0.6689  g_loss:1.5276\n",
      "epoch:209  d_loss:0.5071  g_loss:1.3111\n",
      "epoch:210  d_loss:0.6273  g_loss:1.3449\n",
      "epoch:211  d_loss:0.4608  g_loss:1.5629\n",
      "epoch:212  d_loss:0.5522  g_loss:1.7000\n",
      "epoch:213  d_loss:0.5885  g_loss:1.8209\n",
      "epoch:214  d_loss:0.5494  g_loss:1.2550\n",
      "epoch:215  d_loss:0.4116  g_loss:1.6143\n",
      "epoch:216  d_loss:0.4686  g_loss:1.6146\n",
      "epoch:217  d_loss:0.4041  g_loss:1.3918\n",
      "epoch:218  d_loss:0.4094  g_loss:2.0719\n",
      "epoch:219  d_loss:0.4611  g_loss:2.1282\n",
      "epoch:220  d_loss:0.4331  g_loss:1.9419\n",
      "epoch:221  d_loss:0.4715  g_loss:1.9731\n",
      "epoch:222  d_loss:0.4907  g_loss:1.7782\n",
      "epoch:223  d_loss:0.5330  g_loss:1.4919\n",
      "epoch:224  d_loss:0.5321  g_loss:1.6592\n",
      "epoch:225  d_loss:0.4569  g_loss:1.8847\n",
      "epoch:226  d_loss:0.4499  g_loss:1.9169\n",
      "epoch:227  d_loss:0.5436  g_loss:2.2231\n",
      "epoch:228  d_loss:0.4046  g_loss:1.9330\n",
      "epoch:229  d_loss:0.4270  g_loss:1.6878\n",
      "epoch:230  d_loss:0.4849  g_loss:1.8165\n",
      "epoch:231  d_loss:0.5436  g_loss:1.7599\n",
      "epoch:232  d_loss:0.5080  g_loss:1.9019\n",
      "epoch:233  d_loss:0.6281  g_loss:1.9224\n",
      "epoch:234  d_loss:0.6132  g_loss:1.5601\n",
      "epoch:235  d_loss:0.5459  g_loss:1.4986\n",
      "epoch:236  d_loss:0.6208  g_loss:1.4728\n",
      "epoch:237  d_loss:0.5086  g_loss:1.8436\n",
      "epoch:238  d_loss:0.5287  g_loss:1.8635\n",
      "epoch:239  d_loss:0.4652  g_loss:1.7859\n",
      "epoch:240  d_loss:0.6209  g_loss:1.5556\n",
      "epoch:241  d_loss:0.6717  g_loss:1.2561\n",
      "epoch:242  d_loss:0.6894  g_loss:1.3284\n",
      "epoch:243  d_loss:0.6161  g_loss:1.2793\n",
      "epoch:244  d_loss:0.5121  g_loss:1.2792\n",
      "epoch:245  d_loss:0.4417  g_loss:1.7016\n",
      "epoch:246  d_loss:0.4913  g_loss:1.8388\n",
      "epoch:247  d_loss:0.4955  g_loss:1.5761\n",
      "epoch:248  d_loss:0.4146  g_loss:1.4625\n",
      "epoch:249  d_loss:0.4681  g_loss:1.6769\n",
      "epoch:250  d_loss:0.4434  g_loss:1.6878\n",
      "epoch:251  d_loss:0.4267  g_loss:1.8233\n",
      "epoch:252  d_loss:0.4199  g_loss:1.6571\n",
      "epoch:253  d_loss:0.4488  g_loss:1.8297\n",
      "epoch:254  d_loss:0.4358  g_loss:1.9911\n",
      "epoch:255  d_loss:0.6176  g_loss:1.5846\n",
      "epoch:256  d_loss:0.5573  g_loss:1.4845\n",
      "epoch:257  d_loss:0.5161  g_loss:1.7275\n",
      "epoch:258  d_loss:0.4868  g_loss:1.4383\n",
      "epoch:259  d_loss:0.4355  g_loss:2.0043\n",
      "epoch:260  d_loss:0.4279  g_loss:1.5535\n",
      "epoch:261  d_loss:0.4008  g_loss:1.5554\n",
      "epoch:262  d_loss:0.3922  g_loss:1.6145\n",
      "epoch:263  d_loss:0.4356  g_loss:1.7280\n",
      "epoch:264  d_loss:0.4219  g_loss:1.6633\n",
      "epoch:265  d_loss:0.4406  g_loss:1.7600\n",
      "epoch:266  d_loss:0.3469  g_loss:1.5661\n",
      "epoch:267  d_loss:0.4152  g_loss:1.9144\n",
      "epoch:268  d_loss:0.4469  g_loss:1.6519\n",
      "epoch:269  d_loss:0.5081  g_loss:1.6661\n",
      "epoch:270  d_loss:0.3872  g_loss:1.9883\n",
      "epoch:271  d_loss:0.3963  g_loss:1.8147\n",
      "epoch:272  d_loss:0.4123  g_loss:2.1047\n",
      "epoch:273  d_loss:0.3441  g_loss:2.5188\n",
      "epoch:274  d_loss:0.4004  g_loss:2.3748\n",
      "epoch:275  d_loss:0.3341  g_loss:1.7412\n",
      "epoch:276  d_loss:0.5793  g_loss:1.5739\n",
      "epoch:277  d_loss:0.3898  g_loss:2.2406\n",
      "epoch:278  d_loss:0.3314  g_loss:2.7509\n",
      "epoch:279  d_loss:0.4086  g_loss:2.0387\n",
      "epoch:280  d_loss:0.4073  g_loss:2.2958\n",
      "epoch:281  d_loss:0.4784  g_loss:2.3761\n",
      "epoch:282  d_loss:0.4309  g_loss:2.2288\n",
      "epoch:283  d_loss:0.3261  g_loss:2.6033\n",
      "epoch:284  d_loss:0.6950  g_loss:2.1792\n",
      "epoch:285  d_loss:0.5248  g_loss:2.5442\n",
      "epoch:286  d_loss:0.4218  g_loss:2.1749\n",
      "epoch:287  d_loss:0.5609  g_loss:2.6161\n",
      "epoch:288  d_loss:0.5615  g_loss:2.0125\n",
      "epoch:289  d_loss:0.5418  g_loss:2.0764\n",
      "epoch:290  d_loss:0.6476  g_loss:1.5120\n",
      "epoch:291  d_loss:0.6076  g_loss:1.8622\n",
      "epoch:292  d_loss:0.5368  g_loss:1.8693\n",
      "epoch:293  d_loss:0.4721  g_loss:1.9966\n",
      "epoch:294  d_loss:0.4753  g_loss:1.7378\n",
      "epoch:295  d_loss:0.4258  g_loss:1.7565\n",
      "epoch:296  d_loss:0.4527  g_loss:1.5903\n",
      "epoch:297  d_loss:0.5385  g_loss:1.8494\n",
      "epoch:298  d_loss:0.5743  g_loss:2.1507\n",
      "epoch:299  d_loss:0.4944  g_loss:2.3476\n",
      "epoch:300  d_loss:0.6844  g_loss:1.5115\n",
      "epoch:301  d_loss:0.5186  g_loss:1.6949\n",
      "epoch:302  d_loss:0.4633  g_loss:1.5389\n",
      "epoch:303  d_loss:0.6212  g_loss:1.4578\n",
      "epoch:304  d_loss:0.5639  g_loss:1.8910\n",
      "epoch:305  d_loss:0.5829  g_loss:1.8112\n",
      "epoch:306  d_loss:0.4165  g_loss:1.8676\n",
      "epoch:307  d_loss:0.5256  g_loss:2.0420\n",
      "epoch:308  d_loss:0.3945  g_loss:2.0769\n",
      "epoch:309  d_loss:0.4265  g_loss:2.2937\n",
      "epoch:310  d_loss:0.4980  g_loss:1.7113\n",
      "epoch:311  d_loss:0.3135  g_loss:2.1476\n",
      "epoch:312  d_loss:0.3867  g_loss:1.6490\n",
      "epoch:313  d_loss:0.4107  g_loss:1.7939\n",
      "epoch:314  d_loss:0.3964  g_loss:1.7968\n",
      "epoch:315  d_loss:0.4440  g_loss:1.9039\n",
      "epoch:316  d_loss:0.3360  g_loss:2.0000\n",
      "epoch:317  d_loss:0.3964  g_loss:2.0810\n",
      "epoch:318  d_loss:0.3965  g_loss:2.2198\n",
      "epoch:319  d_loss:0.3759  g_loss:2.5566\n",
      "epoch:320  d_loss:0.4148  g_loss:2.1526\n",
      "epoch:321  d_loss:0.4348  g_loss:1.6337\n",
      "epoch:322  d_loss:0.3928  g_loss:1.7881\n",
      "epoch:323  d_loss:0.3193  g_loss:2.2772\n",
      "epoch:324  d_loss:0.4430  g_loss:2.1075\n",
      "epoch:325  d_loss:0.3770  g_loss:1.9752\n",
      "epoch:326  d_loss:0.4794  g_loss:1.6387\n",
      "epoch:327  d_loss:0.3142  g_loss:2.2617\n",
      "epoch:328  d_loss:0.3425  g_loss:2.0849\n",
      "epoch:329  d_loss:0.4950  g_loss:1.8285\n",
      "epoch:330  d_loss:0.4702  g_loss:2.1275\n",
      "epoch:331  d_loss:0.4979  g_loss:2.2563\n",
      "epoch:332  d_loss:0.5905  g_loss:2.1498\n",
      "epoch:333  d_loss:0.5663  g_loss:1.3030\n",
      "epoch:334  d_loss:0.4793  g_loss:1.4232\n",
      "epoch:335  d_loss:0.5417  g_loss:1.3437\n",
      "epoch:336  d_loss:0.3581  g_loss:1.4202\n",
      "epoch:337  d_loss:0.4378  g_loss:2.0422\n",
      "epoch:338  d_loss:0.4711  g_loss:1.9119\n",
      "epoch:339  d_loss:0.4146  g_loss:2.0750\n",
      "epoch:340  d_loss:0.4125  g_loss:1.8153\n",
      "epoch:341  d_loss:0.5658  g_loss:1.8599\n",
      "epoch:342  d_loss:0.5163  g_loss:1.4257\n",
      "epoch:343  d_loss:0.3909  g_loss:1.7705\n",
      "epoch:344  d_loss:0.4891  g_loss:1.8663\n",
      "epoch:345  d_loss:0.4477  g_loss:1.9285\n",
      "epoch:346  d_loss:0.5204  g_loss:1.6821\n",
      "epoch:347  d_loss:0.4155  g_loss:1.7032\n",
      "epoch:348  d_loss:0.4690  g_loss:1.8263\n",
      "epoch:349  d_loss:0.4660  g_loss:2.3009\n",
      "epoch:350  d_loss:0.4479  g_loss:2.2024\n",
      "epoch:351  d_loss:0.3983  g_loss:2.1000\n",
      "epoch:352  d_loss:0.3975  g_loss:1.8569\n",
      "epoch:353  d_loss:0.3994  g_loss:1.7738\n",
      "epoch:354  d_loss:0.4724  g_loss:1.8359\n",
      "epoch:355  d_loss:0.4118  g_loss:1.7714\n",
      "epoch:356  d_loss:0.4387  g_loss:1.9584\n",
      "epoch:357  d_loss:0.4135  g_loss:2.1010\n",
      "epoch:358  d_loss:0.3107  g_loss:2.2935\n",
      "epoch:359  d_loss:0.3918  g_loss:2.6546\n",
      "epoch:360  d_loss:0.3948  g_loss:2.1739\n",
      "epoch:361  d_loss:0.2940  g_loss:2.1917\n",
      "epoch:362  d_loss:0.3005  g_loss:2.3072\n",
      "epoch:363  d_loss:0.3165  g_loss:2.4009\n",
      "epoch:364  d_loss:0.2056  g_loss:2.5935\n",
      "epoch:365  d_loss:0.3698  g_loss:2.4025\n",
      "epoch:366  d_loss:0.2092  g_loss:3.0673\n",
      "epoch:367  d_loss:0.2264  g_loss:3.0636\n",
      "epoch:368  d_loss:0.3024  g_loss:3.1567\n",
      "epoch:369  d_loss:0.5095  g_loss:2.7422\n",
      "epoch:370  d_loss:0.4554  g_loss:2.8003\n",
      "epoch:371  d_loss:0.2233  g_loss:3.5183\n",
      "epoch:372  d_loss:0.2500  g_loss:3.5288\n",
      "epoch:373  d_loss:0.2383  g_loss:2.7975\n",
      "epoch:374  d_loss:0.2488  g_loss:2.8555\n",
      "epoch:375  d_loss:0.4292  g_loss:3.3476\n",
      "epoch:376  d_loss:0.4333  g_loss:3.4197\n",
      "epoch:377  d_loss:0.3530  g_loss:2.2684\n",
      "epoch:378  d_loss:0.3913  g_loss:2.4989\n",
      "epoch:379  d_loss:0.3594  g_loss:3.6239\n",
      "epoch:380  d_loss:0.5664  g_loss:3.3607\n",
      "epoch:381  d_loss:0.5304  g_loss:2.2928\n",
      "epoch:382  d_loss:0.2941  g_loss:1.9815\n",
      "epoch:383  d_loss:0.4452  g_loss:1.6822\n",
      "epoch:384  d_loss:0.3477  g_loss:1.8588\n",
      "epoch:385  d_loss:0.4107  g_loss:2.2554\n",
      "epoch:386  d_loss:0.4475  g_loss:2.0943\n",
      "epoch:387  d_loss:0.3609  g_loss:2.0341\n",
      "epoch:388  d_loss:0.4580  g_loss:1.8686\n",
      "epoch:389  d_loss:0.3104  g_loss:1.9584\n",
      "epoch:390  d_loss:0.5278  g_loss:1.9980\n",
      "epoch:391  d_loss:0.4022  g_loss:1.6153\n",
      "epoch:392  d_loss:0.5838  g_loss:2.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:393  d_loss:0.5128  g_loss:1.9870\n",
      "epoch:394  d_loss:0.4874  g_loss:1.9703\n",
      "epoch:395  d_loss:0.4709  g_loss:2.5245\n",
      "epoch:396  d_loss:0.3422  g_loss:2.2046\n",
      "epoch:397  d_loss:0.5354  g_loss:2.1470\n",
      "epoch:398  d_loss:0.6695  g_loss:1.7737\n",
      "epoch:399  d_loss:0.5022  g_loss:2.0399\n",
      "epoch:400  d_loss:0.4210  g_loss:2.6209\n",
      "epoch:401  d_loss:0.3791  g_loss:2.2161\n",
      "epoch:402  d_loss:0.4503  g_loss:1.7604\n",
      "epoch:403  d_loss:0.4474  g_loss:1.7514\n",
      "epoch:404  d_loss:0.3727  g_loss:2.2293\n",
      "epoch:405  d_loss:0.3116  g_loss:2.1010\n",
      "epoch:406  d_loss:0.3816  g_loss:1.9880\n",
      "epoch:407  d_loss:0.3658  g_loss:2.2791\n",
      "epoch:408  d_loss:0.3361  g_loss:2.1243\n",
      "epoch:409  d_loss:0.3052  g_loss:2.3161\n",
      "epoch:410  d_loss:0.3042  g_loss:1.7643\n",
      "epoch:411  d_loss:0.3021  g_loss:2.0742\n",
      "epoch:412  d_loss:0.3394  g_loss:1.9717\n",
      "epoch:413  d_loss:0.3601  g_loss:2.0503\n",
      "epoch:414  d_loss:0.3803  g_loss:1.9586\n",
      "epoch:415  d_loss:0.2733  g_loss:2.3414\n",
      "epoch:416  d_loss:0.3568  g_loss:2.1081\n",
      "epoch:417  d_loss:0.3392  g_loss:2.2630\n",
      "epoch:418  d_loss:0.4569  g_loss:1.7046\n",
      "epoch:419  d_loss:0.2981  g_loss:2.4755\n",
      "epoch:420  d_loss:0.2857  g_loss:1.9811\n",
      "epoch:421  d_loss:0.3921  g_loss:2.0003\n",
      "epoch:422  d_loss:0.3170  g_loss:1.8507\n",
      "epoch:423  d_loss:0.4359  g_loss:1.6780\n",
      "epoch:424  d_loss:0.4184  g_loss:1.8717\n",
      "epoch:425  d_loss:0.2499  g_loss:2.2926\n",
      "epoch:426  d_loss:0.3711  g_loss:2.7302\n",
      "epoch:427  d_loss:0.3210  g_loss:2.1900\n",
      "epoch:428  d_loss:0.4116  g_loss:2.6761\n",
      "epoch:429  d_loss:0.4164  g_loss:2.6568\n",
      "epoch:430  d_loss:0.4567  g_loss:2.2518\n",
      "epoch:431  d_loss:0.3729  g_loss:2.2837\n",
      "epoch:432  d_loss:0.5085  g_loss:1.8561\n",
      "epoch:433  d_loss:0.3070  g_loss:2.3446\n",
      "epoch:434  d_loss:0.3801  g_loss:2.2831\n",
      "epoch:435  d_loss:0.3985  g_loss:2.0186\n",
      "epoch:436  d_loss:0.3888  g_loss:2.0680\n",
      "epoch:437  d_loss:0.3817  g_loss:2.2151\n",
      "epoch:438  d_loss:0.3421  g_loss:1.9953\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#이미지가 저장될 폴더가 없다면 만듭니다.\n",
    "import os\n",
    "if not os.path.exists(\"./gan_images\"):\n",
    "    os.makedirs(\"./gan_images\")\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#생성자 모델을 만듭니다.\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "#판별자 모델을 만듭니다.\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "\n",
    "#생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()\n",
    "\n",
    "#신경망을 실행시키는 함수를 만듭니다.\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "\n",
    "  # MNIST 데이터 불러오기\n",
    "\n",
    "  (X_train, _), (_, _) = mnist.load_data()  # 앞서 불러온 적 있는 MNIST를 다시 이용합니다. 단, 테스트과정은 필요없고 이미지만 사용할 것이기 때문에 X_train만 불러왔습니다.\n",
    "  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_train = (X_train - 127.5) / 127.5  # 픽셀값은 0에서 255사이의 값입니다. 이전에 255로 나누어 줄때는 이를 0~1사이의 값으로 바꾸었던 것인데, 여기서는 127.5를 빼준 뒤 127.5로 나누어 줌으로 인해 -1에서 1사이의 값으로 바뀌게 됩니다.\n",
    "  #X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "  true = np.ones((batch_size, 1))\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "\n",
    "  for i in range(epoch):\n",
    "          # 실제 데이터를 판별자에 입력하는 부분입니다.\n",
    "          idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "          imgs = X_train[idx]\n",
    "          d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "          #가상 이미지를 판별자에 입력하는 부분입니다.\n",
    "          noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "          gen_imgs = generator.predict(noise)\n",
    "          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "          #판별자와 생성자의 오차를 계산합니다.\n",
    "          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "          g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        # 이부분은 중간 과정을 이미지로 저장해 주는 부분입니다. 본 장의 주요 내용과 관련이 없어\n",
    "        # 소스코드만 첨부합니다. 만들어진 이미지들은 gan_images 폴더에 저장됩니다.\n",
    "          if i % saving_interval == 0:\n",
    "              #r, c = 5, 5\n",
    "              noise = np.random.normal(0, 1, (25, 100))\n",
    "              gen_imgs = generator.predict(noise)\n",
    "\n",
    "              # Rescale images 0 - 1\n",
    "              gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "              fig, axs = plt.subplots(5, 5)\n",
    "              count = 0\n",
    "              for j in range(5):\n",
    "                  for k in range(5):\n",
    "                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                      axs[j, k].axis('off')\n",
    "                      count += 1\n",
    "              fig.savefig(\"gan_images/gan_mnist_%d.png\" % i)\n",
    "\n",
    "gan_train(4001, 32, 200)  #4000번 반복되고(+1을 해 주는 것에 주의), 배치 사이즈는 32,  200번 마다 결과가 저장되게 하였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
