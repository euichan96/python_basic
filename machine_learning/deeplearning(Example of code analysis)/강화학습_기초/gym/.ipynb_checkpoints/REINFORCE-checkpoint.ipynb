{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03401052,  0.01207753, -0.03297462,  0.03503135])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# State: 카트의 위치, 카트의 속도, 막대기의 각도, 막대기의 회전율\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 뉴럴넷 구성하기\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__(self)\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.hidden_layer_0 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.neural_ans = tf.keras.layers.Dense(self.num_actions, activation = 'tanh')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.convert_to_tensor(inputs)\n",
    "        hidden_0 = self.hidden_layer_0(x)\n",
    "        hidden_1 = self.hidden_layer_1(hidden_0)\n",
    "        neural_ans = self.neural_ans(hidden_1)\n",
    "\n",
    "        return neural_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 창고\n",
    "class Storage():\n",
    "        def __init__(self):\n",
    "            self.total_rewards=[]\n",
    "            self.total_gradients=[]\n",
    "\n",
    "        def save(self, reward, gradient):\n",
    "            gradient = [values.numpy() for values in gradient]\n",
    "            self.total_rewards.append(reward)\n",
    "            self.total_gradients.append(gradient)\n",
    "\n",
    "        def clear(self):\n",
    "            self.total_rewards=[]\n",
    "            self.total_gradients=[]\n",
    "\n",
    "        # 이것이 동작하는 방식이 엄청 중요함!\n",
    "        # 𝐺_𝑡를 계산하기 위한 것\n",
    "        def discounted_rewards(self, discount_factor):\n",
    "            #zeros_like는 그냥 같은 모양의 arry를 만들어 주는 것\n",
    "            discounted_r = np.zeros_like(np.array(self.total_rewards))\n",
    "            running_add = 0\n",
    "            \n",
    "            # 뒤로 뒤집어서 하나씩 곱해준 후 더해주는 것\n",
    "            for t in reversed(range(0, len(np.array(self.total_rewards)))):\n",
    "                # v(t) = reward(현재 시점) + discount_factor * v(t+1)\n",
    "                running_add = np.array(self.total_rewards)[t] + running_add * discount_factor\n",
    "                discounted_r[t] = running_add\n",
    "\n",
    "            return np.array(discounted_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 안녕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain 불러오기\n",
    "class Brain:\n",
    "    def __init__(self, model, storage):\n",
    "        self.model = model\n",
    "        self.storage = storage\n",
    "        self.episode = 0\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        # 모델을 선 build 하는 과정\n",
    "        self.model.build((1,env.observation_space.shape[0]))\n",
    "        self.optimizer = tf.optimizers.Adam(self.learning_rate)\n",
    "\n",
    "\n",
    "    def cost_fn(self, action_list, probability):\n",
    "        # 앞에서 -를 붙이는 이유는? : 이것은 아직 미분을 하기 전이기 때문!\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(action_list*tf.math.log((probability))))\n",
    "        return cost\n",
    "\n",
    "    def action(self, state):\n",
    "        # state inference\n",
    "        probability = self.model([state])\n",
    "        temp_action = tf.random.categorical(probability, 1)                \n",
    "        action = tf.one_hot(temp_action, self.num_actions)\n",
    "        probability = tf.nn.softmax(probability)\n",
    "        return action, probability\n",
    "\n",
    "\n",
    "    def initialize_grad_memory(self, grad_arry):\n",
    "        for idx, grad in enumerate(grad_arry):\n",
    "            grad_arry[idx] = 0\n",
    "\n",
    "\n",
    "    def train(self, env):\n",
    "        # 환경 리셋\n",
    "        state = env.reset()\n",
    "        \n",
    "        # model의 trainable weights와 같은 수의 행렬 생성\n",
    "        grad_arry = self.model.trainable_weights\n",
    "\n",
    "        # 시작하기 전에 grads를 저장할 공간 확보\n",
    "        self.initialize_grad_memory(grad_arry)\n",
    "        update_every = 1\n",
    "        running_reward = 0\n",
    "        sum_rewards = 0\n",
    "\n",
    "        while True:\n",
    "            if self.episode > 1000:\n",
    "                env.render()\n",
    "\n",
    "            # Gradient를 계산하는 공간\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                # 현재 state에서 할 action\n",
    "                action_list, probability = self.action(state)\n",
    "                next_state, reward, done, info = env.step(np.argmax(action_list))\n",
    "                cost = self.cost_fn(action_list, probability)\n",
    "\n",
    "            # cost에 대해서, model.trainable_weights로 미분한 값\n",
    "            grads = tape.gradient(cost, self.model.trainable_weights)\n",
    "            self.storage.save(reward, grads)\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                self.episode += 1\n",
    "                sum_rewards = np.sum(np.array(self.storage.total_rewards))\n",
    "                running_reward = running_reward*0.99+sum_rewards*0.01\n",
    "\n",
    "                saved_gradient = np.array(self.storage.total_gradients)\n",
    "                saved_discounted_rewards = self.storage.discounted_rewards(self.discount_factor)\n",
    "\n",
    "                # Gradinets들을 apply하기 위해서 만드는 작업\n",
    "                # Gt = saved_discounted_rewards\n",
    "                # saved_gradient = 각 위치에서의 w값\n",
    "                for grads, r in zip(saved_gradient, saved_discounted_rewards):\n",
    "                    for idx, grad in enumerate(grads):\n",
    "                        grad_arry[idx] += grad * r\n",
    "                        \n",
    "\n",
    "                # 업데이트 시, 5개씩 모아서 업데이트를 취함\n",
    "                self.optimizer.apply_gradients(zip(grad_arry, model.trainable_variables))\n",
    "                self.initialize_grad_memory(grad_arry)\n",
    "\n",
    "                print(f'run {self.episode} done with score {sum_rewards} and running mean {running_reward}')\n",
    "                self.storage.clear()\n",
    "                state = env.reset()\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  130       \n",
      "=================================================================\n",
      "Total params: 4,610\n",
      "Trainable params: 4,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Layer model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "run 1 done with score 13.0 and running mean 0.13\n",
      "run 2 done with score 29.0 and running mean 0.41869999999999996\n",
      "run 3 done with score 16.0 and running mean 0.5745129999999999\n",
      "run 4 done with score 13.0 and running mean 0.69876787\n",
      "run 5 done with score 50.0 and running mean 1.1917801913\n",
      "run 6 done with score 23.0 and running mean 1.409862389387\n",
      "run 7 done with score 10.0 and running mean 1.49576376549313\n",
      "run 8 done with score 43.0 and running mean 1.9108061278381985\n",
      "run 9 done with score 13.0 and running mean 2.0216980665598165\n",
      "run 10 done with score 11.0 and running mean 2.1114810858942183\n",
      "run 11 done with score 24.0 and running mean 2.330366275035276\n",
      "run 12 done with score 21.0 and running mean 2.5170626122849233\n",
      "run 13 done with score 12.0 and running mean 2.611891986162074\n",
      "run 14 done with score 27.0 and running mean 2.8557730663004532\n",
      "run 15 done with score 29.0 and running mean 3.117215335637449\n",
      "run 16 done with score 14.0 and running mean 3.2260431822810745\n",
      "run 17 done with score 16.0 and running mean 3.353782750458264\n",
      "run 18 done with score 13.0 and running mean 3.450244922953681\n",
      "run 19 done with score 24.0 and running mean 3.6557424737241444\n",
      "run 20 done with score 22.0 and running mean 3.839185048986903\n",
      "run 21 done with score 15.0 and running mean 3.950793198497034\n",
      "run 22 done with score 20.0 and running mean 4.111285266512064\n",
      "run 23 done with score 18.0 and running mean 4.2501724138469426\n",
      "run 24 done with score 20.0 and running mean 4.407670689708473\n",
      "run 25 done with score 19.0 and running mean 4.553593982811389\n",
      "run 26 done with score 38.0 and running mean 4.888058042983275\n",
      "run 27 done with score 14.0 and running mean 4.979177462553442\n",
      "run 28 done with score 32.0 and running mean 5.249385687927908\n",
      "run 29 done with score 24.0 and running mean 5.436891831048629\n",
      "run 30 done with score 25.0 and running mean 5.632522912738143\n",
      "run 31 done with score 29.0 and running mean 5.866197683610761\n",
      "run 32 done with score 23.0 and running mean 6.037535706774654\n",
      "run 33 done with score 14.0 and running mean 6.117160349706907\n",
      "run 34 done with score 67.0 and running mean 6.725988746209838\n",
      "run 35 done with score 19.0 and running mean 6.84872885874774\n",
      "run 36 done with score 22.0 and running mean 7.000241570160262\n",
      "run 37 done with score 34.0 and running mean 7.270239154458659\n",
      "run 38 done with score 40.0 and running mean 7.597536762914073\n",
      "run 39 done with score 12.0 and running mean 7.641561395284932\n",
      "run 40 done with score 34.0 and running mean 7.905145781332083\n",
      "run 41 done with score 14.0 and running mean 7.966094323518761\n",
      "run 42 done with score 18.0 and running mean 8.066433380283573\n",
      "run 43 done with score 18.0 and running mean 8.165769046480738\n",
      "run 44 done with score 28.0 and running mean 8.36411135601593\n",
      "run 45 done with score 35.0 and running mean 8.630470242455772\n",
      "run 46 done with score 17.0 and running mean 8.714165540031214\n",
      "run 47 done with score 74.0 and running mean 9.367023884630902\n",
      "run 48 done with score 20.0 and running mean 9.473353645784591\n",
      "run 49 done with score 32.0 and running mean 9.698620109326745\n",
      "run 50 done with score 22.0 and running mean 9.821633908233478\n",
      "run 51 done with score 32.0 and running mean 10.043417569151144\n",
      "run 52 done with score 13.0 and running mean 10.072983393459634\n",
      "run 53 done with score 37.0 and running mean 10.342253559525036\n",
      "run 54 done with score 17.0 and running mean 10.408831023929785\n",
      "run 55 done with score 30.0 and running mean 10.604742713690488\n",
      "run 56 done with score 43.0 and running mean 10.928695286553582\n",
      "run 57 done with score 25.0 and running mean 11.069408333688045\n",
      "run 58 done with score 22.0 and running mean 11.178714250351165\n",
      "run 59 done with score 41.0 and running mean 11.476927107847652\n",
      "run 60 done with score 71.0 and running mean 12.072157836769176\n",
      "run 61 done with score 97.0 and running mean 12.921436258401485\n",
      "run 62 done with score 23.0 and running mean 13.02222189581747\n",
      "run 63 done with score 32.0 and running mean 13.211999676859296\n",
      "run 64 done with score 40.0 and running mean 13.479879680090704\n",
      "run 65 done with score 48.0 and running mean 13.825080883289797\n",
      "run 66 done with score 49.0 and running mean 14.176830074456898\n",
      "run 67 done with score 40.0 and running mean 14.435061773712329\n",
      "run 68 done with score 25.0 and running mean 14.540711155975206\n",
      "run 69 done with score 46.0 and running mean 14.855304044415455\n",
      "run 70 done with score 70.0 and running mean 15.4067510039713\n",
      "run 71 done with score 36.0 and running mean 15.612683493931586\n",
      "run 72 done with score 36.0 and running mean 15.816556658992269\n",
      "run 73 done with score 27.0 and running mean 15.928391092402347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2e19ccbf0c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8a0b384e5323>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# 현재 state에서 할 action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0maction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8a0b384e5323>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# state inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtemp_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_cast_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1755\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_defaulted_to_floatx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_about_input_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m           \u001b[0;31m# Inputs may be TensorSpecs when this function is called from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    689\u001b[0m   \u001b[0mbase_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   if isinstance(x,\n\u001b[0;32m--> 691\u001b[0;31m                 (ops.Tensor, _resource_variable_type)) and base_type == x.dtype:\n\u001b[0m\u001b[1;32m    692\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    259\u001b[0m                                other.base_dtype.as_datatype_enum)\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;34m\"\"\"Returns True iff this DType refers to the same type as `other`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "storage = Storage()\n",
    "agent = Brain(model, storage)\n",
    "model.summary()\n",
    "agent.train(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5288473+0.47115272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999993"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5144196+0.48558033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
