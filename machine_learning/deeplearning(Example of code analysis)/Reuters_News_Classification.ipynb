{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfYcefdBp5Om"
   },
   "outputs": [],
   "source": [
    "  !sudo apt-get install -y fonts-nanum\n",
    "  !sudo fc-cache -fv\n",
    "  !rm ~/.cache/matplotlib -rf\n",
    "\n",
    "  # 이 셀 실행후, 런타임 다시시작\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ou9Oma8wK93q"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='NanumBarunGothic')     # 한글 폰트\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', unicode_minus=False)           # 유니코드 \"-\" sign\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.datasets import reuters\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OKkyP9HFLXzU"
   },
   "outputs": [],
   "source": [
    "# global constants and hyper-parameters\n",
    "MY_SAMPLE = 2947\n",
    "NUM_CLASS = 46          # Classification class\n",
    "MY_NUM_WORDS = 2000     # number of words in dictionary\n",
    "\n",
    "\n",
    "MY_HIDDEN = 512         # \n",
    "MY_DROPOUT = 0.5        # Dropout rate : temporarily dropout given rate of cell's outputs to \"0\" : like Regularization\n",
    "\n",
    "MY_EPOCH = 10\n",
    "MY_BATCH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yMUJFzAsMF4A"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# DATABASE SETTING #\n",
    "####################\n",
    "# there are 46 news categories in reuters DB\n",
    "labels = ['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
    "          'housing','money-supply','coffee','sugar','trade','reserves', \n",
    "          'ship','cotton','carcass','crude','nat-gas','cpi','money-fx',\n",
    "          'interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "          'strategic-metal','livestock','retail','ipi','iron-steel',\n",
    "          'rubber','heat','jobs','lei','bop','zinc','orange',\n",
    "          'pet- chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CQ88jndsMktS"
   },
   "outputs": [],
   "source": [
    "# print shape information\n",
    "def show_shape():\n",
    "  print('\\n== DB SHAPE INFO ==')\n",
    "  print('X_train shape = ', X_train.shape)\n",
    "  print('X_test shape = ', X_test.shape)\n",
    "  print('Y_train shape = ', Y_train.shape)\n",
    "  print('Y_test shape = ', Y_test.shape) \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S37tReOSMq80",
    "outputId": "23324512-8195-41b7-9b48-3515e25e5e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== DB SHAPE INFO ==\n",
      "X_train shape =  (7859,)\n",
      "X_test shape =  (3369,)\n",
      "Y_train shape =  (7859,)\n",
      "Y_test shape =  (3369,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the DB and print shape info\n",
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = MY_NUM_WORDS, test_split = 0.3)\n",
    "\n",
    "show_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pWrke2Bm3f6",
    "outputId": "a3a59b93-e234-49d7-c159-3b3536a00631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwKoV3cdMyhl",
    "outputId": "2171241a-51d1-4aad-9ffc-017f39d55d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== TRAIN DATA CONTENT INFO ==\n",
      "0 cocoa = 50\n",
      "1 grain = 378\n",
      "2 veg-oil = 66\n",
      "3 earn = 2769\n",
      "4 acq = 1701\n",
      "5 wheat = 14\n",
      "6 copper = 39\n",
      "7 housing = 15\n",
      "8 money-supply = 126\n",
      "9 coffee = 93\n",
      "10 sugar = 114\n",
      "11 trade = 337\n",
      "12 reserves = 40\n",
      "13 ship = 149\n",
      "14 cotton = 18\n",
      "15 carcass = 19\n",
      "16 crude = 387\n",
      "17 nat-gas = 33\n",
      "18 cpi = 59\n",
      "19 money-fx = 475\n",
      "20 interest = 238\n",
      "21 gnp = 91\n",
      "22 meal-feed = 10\n",
      "23 alum = 36\n",
      "24 oilseed = 56\n",
      "25 gold = 77\n",
      "26 tin = 18\n",
      "27 strategic-metal = 13\n",
      "28 livestock = 43\n",
      "29 retail = 19\n",
      "30 ipi = 38\n",
      "31 iron-steel = 34\n",
      "32 rubber = 30\n",
      "33 heat = 9\n",
      "34 jobs = 43\n",
      "35 lei = 10\n",
      "36 bop = 46\n",
      "37 zinc = 17\n",
      "38 orange = 16\n",
      "39 pet- chem = 20\n",
      "40 dlr = 32\n",
      "41 gas = 28\n",
      "42 silver = 10\n",
      "43 wpi = 19\n",
      "44 hog = 10\n",
      "45 lead = 14\n"
     ]
    }
   ],
   "source": [
    "# statistics on how many articles per category in the train DB\n",
    "# numpy unique is useful in this case\n",
    "print('\\n== TRAIN DATA CONTENT INFO ==')\n",
    "unique, counts = np.unique(Y_train, return_counts = True)\n",
    "for i in range(len(unique)):\n",
    "  print(unique[i], labels[i], \"=\", counts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaL6dV50M7J8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dk48PHbRM4Ca"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# my_array = [1, 1, 2, 2, 2, 3]\n",
    "# unique, count = np.unique(my_array, return_counts = True)\n",
    "\n",
    "# # print the result\n",
    "# print(unique)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjtNNu1WnXfs",
    "outputId": "363082cc-7d9d-45ca-b6f2-565600e0bfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  3 ...  4 16  3]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "[  50  378   66 2769 1701   14   39   15  126   93  114  337   40  149\n",
      "   18   19  387   33   59  475  238   91   10   36   56   77   18   13\n",
      "   43   19   38   34   30    9   43   10   46   17   16   20   32   28\n",
      "   10   19   10   14]\n"
     ]
    }
   ],
   "source": [
    "unique, count = np.unique(Y_train, return_counts=True)\n",
    "print(Y_train)    # 7859\n",
    "print(unique)     # Category\n",
    "print(count)      # records per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "-nV-bI_mNExt",
    "outputId": "442b4f6c-ef0f-4256-d6a0-b5c50ac55103"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the same statistics visually\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(1)\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(Y_train, bins='auto')\n",
    "plt.xlabel(\"카테고리\")\n",
    "plt.ylabel(\"Number of occurrences\")\n",
    "plt.title(\"Train data\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(Y_test, bins='auto')\n",
    "plt.xlabel(\"카테고리\")\n",
    "plt.ylabel(\"Number of occurrences\")\n",
    "plt.title(\"Test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCct_CMPNIXU",
    "outputId": "3b83eebc-0b90-40c5-f8f8-2bdcb79b1094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SAMPLE ARTICLE (RAW) ==\n",
      "article # 2947\n",
      "category 4 acq\n",
      "number of words 61\n",
      "[1, 2, 1229, 81, 8, 16, 515, 25, 270, 5, 4, 2, 1229, 111, 267, 7, 73, 2, 2, 7, 108, 13, 80, 1448, 28, 365, 12, 11, 15, 1986, 2, 69, 158, 18, 1296, 1275, 7, 2, 1627, 2, 2, 4, 393, 374, 1229, 323, 5, 2, 1229, 7, 2, 9, 25, 2, 473, 936, 4, 49, 8, 17, 12]\n",
      "\n",
      "== DICTIONARY INFO ==\n",
      "There are 30980 words in the dictionary.\n",
      "The index of \"the\" is 1\n"
     ]
    }
   ],
   "source": [
    "# show a sample data in its raw format\n",
    "print('\\n== SAMPLE ARTICLE (RAW) ==')\n",
    "print(\"article #\", MY_SAMPLE)\n",
    "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])\n",
    "print(\"number of words\", len(X_train[MY_SAMPLE]))\n",
    "print(X_train[MY_SAMPLE])\n",
    "\n",
    "# python dictionary: word -> index\n",
    "# zero index is not used\n",
    "word_to_id = reuters.get_word_index()\n",
    "print('\\n== DICTIONARY INFO ==')\n",
    "print(\"There are\", len(word_to_id) + 1, \"words in the dictionary.\")\n",
    "print('The index of \"the\" is', word_to_id['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fwaJEa8GNT4R"
   },
   "outputs": [],
   "source": [
    "# python dictionary: index -> word\n",
    "# this is the opposite to word_to_id dictionary\n",
    "id_to_word = {}\n",
    "for key, value in word_to_id.items():\n",
    "  id_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "fH2_oAl6NXW0"
   },
   "outputs": [],
   "source": [
    "# function to translate the sample review\n",
    "# we use python dictionary get() function\n",
    "# it returns \"???\" if the ID is not found\n",
    "# index is subtracted by 3 to handle first 3 special characters\n",
    "#   index 0 is for padding (= filling empty space)\n",
    "#   index 1 is for indicating the beginning of a review\n",
    "#   index 2 is for dropped word (= out of bound)\n",
    "# we use python list and join() function to concatenate the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meJ0vAPXNhAk",
    "outputId": "76a8aed8-12e9-41ea-d6c4-37e77369fc68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SAMPLE ARTICLE (DECODED) ==\n",
      "??? ??? telephone corp said it completed its acquisition of the ??? telephone co based in new ??? ??? in exchange for stock valued at 26 3 mln dlrs enterprises ??? about 16 000 access lines in ??? county ??? ??? the third operating telephone subsidiary of ??? telephone in ??? and its ??? largest overall the company said reuter 3\n",
      "category 4 acq\n"
     ]
    }
   ],
   "source": [
    "def decoding():\n",
    "  decoded = []\n",
    "  for i in X_train[MY_SAMPLE]:\n",
    "    word = id_to_word.get(i - 3, \"???\")\n",
    "    decoded.append(word)\n",
    "\n",
    "  print('\\n== SAMPLE ARTICLE (DECODED) ==')\n",
    "  print(\" \".join(decoded))\n",
    "  \n",
    "decoding()\n",
    "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21DXQk4-Nt0s",
    "outputId": "2f168cb8-c772-4cec-843f-b90831e3749d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "number before: 87\n",
      "after: [0. 1. 4. ... 0. 0. 0.]\n",
      "number after: 2000\n"
     ]
    }
   ],
   "source": [
    "# we will NOT do padding (as in movie review classification)\n",
    "# instead we will do tokenization for the inputs\n",
    "# we get a numpy array of size MY_NUM_WORDS for each input \n",
    "# the entries are integer counts \n",
    "# the resulting matrix is very big\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# for i in range(10):\n",
    "#   print(len(X_train[i]))\n",
    "\n",
    "Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
    "\n",
    "print('before:', X_train[0])\n",
    "print('number before:', len(X_train[0]))\n",
    "X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
    "print('after:', X_train[0])\n",
    "print('number after:', len(X_train[0]))\n",
    "\n",
    "X_test = Tok.sequences_to_matrix(X_test, mode = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6IvUSlAuxkw",
    "outputId": "2663468a-ac3c-44b1-a824-df7d0183a26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SAMPLE ARTICLE (TOKENIZED INPUT) ==\n",
      "0.0 1.0 11.0 0.0 3.0 2.0 0.0 4.0 2.0 1.0 0.0 1.0 2.0 1.0 0.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "Array size: 2000\n",
      "Sum of entries: 61.0\n"
     ]
    }
   ],
   "source": [
    "# Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
    "# X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
    "# X_test = Tok.sequences_to_matrix(X_test, mode = 'count’)\n",
    "\n",
    "print('\\n== SAMPLE ARTICLE (TOKENIZED INPUT) ==')\n",
    "sample = X_train[MY_SAMPLE]\n",
    "print(*sample, sep = ' ')\n",
    "print(\"Array size:\", len(sample))\n",
    "print(\"Sum of entries:\", np.sum(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOnatkWcN8Z5",
    "outputId": "57ea5f77-95e3-4c1b-df55-949fe71f03a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Array size: 46\n",
      "\n",
      "== DB SHAPE INFO ==\n",
      "X_train shape =  (7859, 2000)\n",
      "X_test shape =  (3369, 2000)\n",
      "Y_train shape =  (7859, 46)\n",
      "Y_test shape =  (3369, 46)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output reshaping using one-hot encoding\n",
    "# from keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, NUM_CLASS)\n",
    "Y_test = to_categorical(Y_test, NUM_CLASS)\n",
    "\n",
    "print('\\n== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==')\n",
    "sample = Y_train[MY_SAMPLE]\n",
    "print(sample)\n",
    "print(\"Array size:\", len(sample))\n",
    "\n",
    "show_shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xapmZb7pN_ZW",
    "outputId": "53417ea6-10f8-486a-e5e5-4d0e73500058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 512)               1024512   \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 46)                23598     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 46)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,048,110\n",
      "Trainable params: 1,048,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# MODEL BUILDING AND TRAINING #\n",
    "###############################\n",
    "# build a keras sequential model of our DNN\n",
    "# softmax is needed for multi-class classification\n",
    "model = Sequential()\n",
    "model.add(Dense(units=MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))\n",
    "# model.add(Dense(MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))  => have to give Tuple, eg (MY_NUM_WORDS,)\n",
    "model.add(Activation('relu'))       # later comment this out or use others, \n",
    "model.add(Dropout(MY_DROPOUT))\n",
    "model.add(Dense(NUM_CLASS))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BtHybqwOJYC",
    "outputId": "f00d98c9-6c0d-43cc-d49c-58f65ce9b954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SAMPLE QUESTION ==\n",
      "My guess for sample article: 35 lei\n",
      "The answer is: 4 acq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction using the model\n",
    "# shape needs to change from (2000,) to (1, 2000)\n",
    "def ask_question():\n",
    "  sample = X_train[MY_SAMPLE]\n",
    "  sample = sample.reshape(1, sample.shape[0])\n",
    "  pred = model.predict(sample, verbose = 0)\n",
    "  guess = np.argmax(pred)\n",
    "  answer = np.argmax(Y_train[MY_SAMPLE])\n",
    "  \n",
    "  print('\\n== SAMPLE QUESTION ==')\n",
    "  print(\"My guess for sample article:\", guess, labels[guess])\n",
    "  print(\"The answer is:\", answer, labels[answer]) \n",
    "  print()\n",
    "\n",
    "ask_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXNO6YchOQpM",
    "outputId": "517dba4f-ff47-432a-bb3c-5d7a750fd296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 1.6603 - accuracy: 0.6703 - val_loss: 1.0944 - val_accuracy: 0.7685\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.8359 - accuracy: 0.8197 - val_loss: 0.9142 - val_accuracy: 0.8068\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.8712 - val_loss: 0.8810 - val_accuracy: 0.8097\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.4280 - accuracy: 0.8994 - val_loss: 0.8910 - val_accuracy: 0.8124\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3414 - accuracy: 0.9164 - val_loss: 0.9084 - val_accuracy: 0.8059\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2781 - accuracy: 0.9327 - val_loss: 0.9289 - val_accuracy: 0.8091\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2570 - accuracy: 0.9352 - val_loss: 0.9540 - val_accuracy: 0.8100\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2188 - accuracy: 0.9450 - val_loss: 0.9592 - val_accuracy: 0.8139\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9476 - val_loss: 1.0203 - val_accuracy: 0.8085\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9477 - val_loss: 1.0064 - val_accuracy: 0.8088\n"
     ]
    }
   ],
   "source": [
    "# model training and saving\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = MY_EPOCH, batch_size = MY_BATCH, verbose = 1)\n",
    "model.save('chap2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6jJWOAwObWy",
    "outputId": "93de7fe4-e877-467c-c6b4-c548f2b66eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 2ms/step - loss: 1.0064 - accuracy: 0.8088\n",
      "Test loss: 1.0064332485198975\n",
      "Test accuracy: 0.8088453412055969\n",
      "Prediction for the first news:  [2.7493418e-06 1.7930518e-04 5.5374071e-06 9.9746323e-01 1.7143703e-04\n",
      " 2.1166838e-06 2.3480600e-06 5.1803522e-06 5.6914228e-05 4.2390482e-05\n",
      " 2.8156883e-05 1.7351695e-04 2.6283012e-04 2.6022961e-05 2.0473553e-05\n",
      " 5.8581657e-07 4.4142629e-04 1.0307259e-06 6.5133950e-06 2.3461308e-04\n",
      " 6.0140353e-04 5.8141406e-05 2.0386528e-06 5.0484387e-06 3.2164909e-05\n",
      " 5.9265444e-06 2.1546148e-06 3.7750507e-07 2.3484667e-05 1.4818933e-06\n",
      " 2.7955835e-05 2.3716907e-06 3.2516946e-05 1.5722632e-06 9.2987748e-06\n",
      " 6.9669147e-07 2.1078158e-05 1.4238011e-06 2.5588452e-05 7.3013058e-07\n",
      " 4.2835168e-06 5.2252489e-07 1.6919765e-06 3.0347583e-06 2.2750962e-07\n",
      " 8.3083050e-06]\n",
      "3\n",
      "Answer:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "earn\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# MODEL EVALUATION #\n",
    "####################\n",
    "# evaluate the model and calculate loss and accuracy\n",
    "score = model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print('Prediction for the first news: ', pred[0])\n",
    "print(np.argmax(pred[0])) \n",
    "print('Answer: ', Y_test[0])\n",
    "print(labels[np.argmax(Y_test[0])]) \n",
    "\n",
    "\n",
    "# ask_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "자연어처리 기초 Reuters News Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
