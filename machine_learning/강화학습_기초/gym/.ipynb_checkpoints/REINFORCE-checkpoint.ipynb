{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03401052,  0.01207753, -0.03297462,  0.03503135])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# State: Ïπ¥Ìä∏Ïùò ÏúÑÏπò, Ïπ¥Ìä∏Ïùò ÏÜçÎèÑ, ÎßâÎåÄÍ∏∞Ïùò Í∞ÅÎèÑ, ÎßâÎåÄÍ∏∞Ïùò ÌöåÏ†ÑÏú®\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏÇ¨Ïö©Ìï† Îâ¥Îü¥ÎÑ∑ Íµ¨ÏÑ±ÌïòÍ∏∞\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__(self)\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.hidden_layer_0 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.neural_ans = tf.keras.layers.Dense(self.num_actions, activation = 'tanh')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.convert_to_tensor(inputs)\n",
    "        hidden_0 = self.hidden_layer_0(x)\n",
    "        hidden_1 = self.hidden_layer_1(hidden_0)\n",
    "        neural_ans = self.neural_ans(hidden_1)\n",
    "\n",
    "        return neural_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÄÏû• Ï∞ΩÍ≥†\n",
    "class Storage():\n",
    "        def __init__(self):\n",
    "            self.total_rewards=[]\n",
    "            self.total_gradients=[]\n",
    "\n",
    "        def save(self, reward, gradient):\n",
    "            gradient = [values.numpy() for values in gradient]\n",
    "            self.total_rewards.append(reward)\n",
    "            self.total_gradients.append(gradient)\n",
    "\n",
    "        def clear(self):\n",
    "            self.total_rewards=[]\n",
    "            self.total_gradients=[]\n",
    "\n",
    "        # Ïù¥Í≤ÉÏù¥ ÎèôÏûëÌïòÎäî Î∞©ÏãùÏù¥ ÏóÑÏ≤≠ Ï§ëÏöîÌï®!\n",
    "        # ùê∫_ùë°Î•º Í≥ÑÏÇ∞ÌïòÍ∏∞ ÏúÑÌïú Í≤É\n",
    "        def discounted_rewards(self, discount_factor):\n",
    "            #zeros_likeÎäî Í∑∏ÎÉ• Í∞ôÏùÄ Î™®ÏñëÏùò arryÎ•º ÎßåÎì§Ïñ¥ Ï£ºÎäî Í≤É\n",
    "            discounted_r = np.zeros_like(np.array(self.total_rewards))\n",
    "            running_add = 0\n",
    "            \n",
    "            # Îí§Î°ú Îí§ÏßëÏñ¥ÏÑú ÌïòÎÇòÏî© Í≥±Ìï¥Ï§Ä ÌõÑ ÎçîÌï¥Ï£ºÎäî Í≤É\n",
    "            for t in reversed(range(0, len(np.array(self.total_rewards)))):\n",
    "                # v(t) = reward(ÌòÑÏû¨ ÏãúÏ†ê) + discount_factor * v(t+1)\n",
    "                running_add = np.array(self.total_rewards)[t] + running_add * discount_factor\n",
    "                discounted_r[t] = running_add\n",
    "\n",
    "            return np.array(discounted_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏïàÎÖï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain Î∂àÎü¨Ïò§Í∏∞\n",
    "class Brain:\n",
    "    def __init__(self, model, storage):\n",
    "        self.model = model\n",
    "        self.storage = storage\n",
    "        self.episode = 0\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        # Î™®Îç∏ÏùÑ ÏÑ† build ÌïòÎäî Í≥ºÏ†ï\n",
    "        self.model.build((1,env.observation_space.shape[0]))\n",
    "        self.optimizer = tf.optimizers.Adam(self.learning_rate)\n",
    "\n",
    "\n",
    "    def cost_fn(self, action_list, probability):\n",
    "        # ÏïûÏóêÏÑú -Î•º Î∂ôÏù¥Îäî Ïù¥Ïú†Îäî? : Ïù¥Í≤ÉÏùÄ ÏïÑÏßÅ ÎØ∏Î∂ÑÏùÑ ÌïòÍ∏∞ Ï†ÑÏù¥Í∏∞ ÎïåÎ¨∏!\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(action_list*tf.math.log((probability))))\n",
    "        return cost\n",
    "\n",
    "    def action(self, state):\n",
    "        # state inference\n",
    "        probability = self.model([state])\n",
    "        temp_action = tf.random.categorical(probability, 1)                \n",
    "        action = tf.one_hot(temp_action, self.num_actions)\n",
    "        probability = tf.nn.softmax(probability)\n",
    "        return action, probability\n",
    "\n",
    "\n",
    "    def initialize_grad_memory(self, grad_arry):\n",
    "        for idx, grad in enumerate(grad_arry):\n",
    "            grad_arry[idx] = 0\n",
    "\n",
    "\n",
    "    def train(self, env):\n",
    "        # ÌôòÍ≤Ω Î¶¨ÏÖã\n",
    "        state = env.reset()\n",
    "        \n",
    "        # modelÏùò trainable weightsÏôÄ Í∞ôÏùÄ ÏàòÏùò ÌñâÎ†¨ ÏÉùÏÑ±\n",
    "        grad_arry = self.model.trainable_weights\n",
    "\n",
    "        # ÏãúÏûëÌïòÍ∏∞ Ï†ÑÏóê gradsÎ•º Ï†ÄÏû•Ìï† Í≥µÍ∞Ñ ÌôïÎ≥¥\n",
    "        self.initialize_grad_memory(grad_arry)\n",
    "        update_every = 1\n",
    "        running_reward = 0\n",
    "        sum_rewards = 0\n",
    "\n",
    "        while True:\n",
    "            if self.episode > 1000:\n",
    "                env.render()\n",
    "\n",
    "            # GradientÎ•º Í≥ÑÏÇ∞ÌïòÎäî Í≥µÍ∞Ñ\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                # ÌòÑÏû¨ stateÏóêÏÑú Ìï† action\n",
    "                action_list, probability = self.action(state)\n",
    "                next_state, reward, done, info = env.step(np.argmax(action_list))\n",
    "                cost = self.cost_fn(action_list, probability)\n",
    "\n",
    "            # costÏóê ÎåÄÌï¥ÏÑú, model.trainable_weightsÎ°ú ÎØ∏Î∂ÑÌïú Í∞í\n",
    "            grads = tape.gradient(cost, self.model.trainable_weights)\n",
    "            self.storage.save(reward, grads)\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                self.episode += 1\n",
    "                sum_rewards = np.sum(np.array(self.storage.total_rewards))\n",
    "                running_reward = running_reward*0.99+sum_rewards*0.01\n",
    "\n",
    "                saved_gradient = np.array(self.storage.total_gradients)\n",
    "                saved_discounted_rewards = self.storage.discounted_rewards(self.discount_factor)\n",
    "\n",
    "                # GradinetsÎì§ÏùÑ applyÌïòÍ∏∞ ÏúÑÌï¥ÏÑú ÎßåÎìúÎäî ÏûëÏóÖ\n",
    "                # Gt = saved_discounted_rewards\n",
    "                # saved_gradient = Í∞Å ÏúÑÏπòÏóêÏÑúÏùò wÍ∞í\n",
    "                for grads, r in zip(saved_gradient, saved_discounted_rewards):\n",
    "                    for idx, grad in enumerate(grads):\n",
    "                        grad_arry[idx] += grad * r\n",
    "                        \n",
    "\n",
    "                # ÏóÖÎç∞Ïù¥Ìä∏ Ïãú, 5Í∞úÏî© Î™®ÏïÑÏÑú ÏóÖÎç∞Ïù¥Ìä∏Î•º Ï∑®Ìï®\n",
    "                self.optimizer.apply_gradients(zip(grad_arry, model.trainable_variables))\n",
    "                self.initialize_grad_memory(grad_arry)\n",
    "\n",
    "                print(f'run {self.episode} done with score {sum_rewards} and running mean {running_reward}')\n",
    "                self.storage.clear()\n",
    "                state = env.reset()\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  130       \n",
      "=================================================================\n",
      "Total params: 4,610\n",
      "Trainable params: 4,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Layer model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "run 1 done with score 13.0 and running mean 0.13\n",
      "run 2 done with score 29.0 and running mean 0.41869999999999996\n",
      "run 3 done with score 16.0 and running mean 0.5745129999999999\n",
      "run 4 done with score 13.0 and running mean 0.69876787\n",
      "run 5 done with score 50.0 and running mean 1.1917801913\n",
      "run 6 done with score 23.0 and running mean 1.409862389387\n",
      "run 7 done with score 10.0 and running mean 1.49576376549313\n",
      "run 8 done with score 43.0 and running mean 1.9108061278381985\n",
      "run 9 done with score 13.0 and running mean 2.0216980665598165\n",
      "run 10 done with score 11.0 and running mean 2.1114810858942183\n",
      "run 11 done with score 24.0 and running mean 2.330366275035276\n",
      "run 12 done with score 21.0 and running mean 2.5170626122849233\n",
      "run 13 done with score 12.0 and running mean 2.611891986162074\n",
      "run 14 done with score 27.0 and running mean 2.8557730663004532\n",
      "run 15 done with score 29.0 and running mean 3.117215335637449\n",
      "run 16 done with score 14.0 and running mean 3.2260431822810745\n",
      "run 17 done with score 16.0 and running mean 3.353782750458264\n",
      "run 18 done with score 13.0 and running mean 3.450244922953681\n",
      "run 19 done with score 24.0 and running mean 3.6557424737241444\n",
      "run 20 done with score 22.0 and running mean 3.839185048986903\n",
      "run 21 done with score 15.0 and running mean 3.950793198497034\n",
      "run 22 done with score 20.0 and running mean 4.111285266512064\n",
      "run 23 done with score 18.0 and running mean 4.2501724138469426\n",
      "run 24 done with score 20.0 and running mean 4.407670689708473\n",
      "run 25 done with score 19.0 and running mean 4.553593982811389\n",
      "run 26 done with score 38.0 and running mean 4.888058042983275\n",
      "run 27 done with score 14.0 and running mean 4.979177462553442\n",
      "run 28 done with score 32.0 and running mean 5.249385687927908\n",
      "run 29 done with score 24.0 and running mean 5.436891831048629\n",
      "run 30 done with score 25.0 and running mean 5.632522912738143\n",
      "run 31 done with score 29.0 and running mean 5.866197683610761\n",
      "run 32 done with score 23.0 and running mean 6.037535706774654\n",
      "run 33 done with score 14.0 and running mean 6.117160349706907\n",
      "run 34 done with score 67.0 and running mean 6.725988746209838\n",
      "run 35 done with score 19.0 and running mean 6.84872885874774\n",
      "run 36 done with score 22.0 and running mean 7.000241570160262\n",
      "run 37 done with score 34.0 and running mean 7.270239154458659\n",
      "run 38 done with score 40.0 and running mean 7.597536762914073\n",
      "run 39 done with score 12.0 and running mean 7.641561395284932\n",
      "run 40 done with score 34.0 and running mean 7.905145781332083\n",
      "run 41 done with score 14.0 and running mean 7.966094323518761\n",
      "run 42 done with score 18.0 and running mean 8.066433380283573\n",
      "run 43 done with score 18.0 and running mean 8.165769046480738\n",
      "run 44 done with score 28.0 and running mean 8.36411135601593\n",
      "run 45 done with score 35.0 and running mean 8.630470242455772\n",
      "run 46 done with score 17.0 and running mean 8.714165540031214\n",
      "run 47 done with score 74.0 and running mean 9.367023884630902\n",
      "run 48 done with score 20.0 and running mean 9.473353645784591\n",
      "run 49 done with score 32.0 and running mean 9.698620109326745\n",
      "run 50 done with score 22.0 and running mean 9.821633908233478\n",
      "run 51 done with score 32.0 and running mean 10.043417569151144\n",
      "run 52 done with score 13.0 and running mean 10.072983393459634\n",
      "run 53 done with score 37.0 and running mean 10.342253559525036\n",
      "run 54 done with score 17.0 and running mean 10.408831023929785\n",
      "run 55 done with score 30.0 and running mean 10.604742713690488\n",
      "run 56 done with score 43.0 and running mean 10.928695286553582\n",
      "run 57 done with score 25.0 and running mean 11.069408333688045\n",
      "run 58 done with score 22.0 and running mean 11.178714250351165\n",
      "run 59 done with score 41.0 and running mean 11.476927107847652\n",
      "run 60 done with score 71.0 and running mean 12.072157836769176\n",
      "run 61 done with score 97.0 and running mean 12.921436258401485\n",
      "run 62 done with score 23.0 and running mean 13.02222189581747\n",
      "run 63 done with score 32.0 and running mean 13.211999676859296\n",
      "run 64 done with score 40.0 and running mean 13.479879680090704\n",
      "run 65 done with score 48.0 and running mean 13.825080883289797\n",
      "run 66 done with score 49.0 and running mean 14.176830074456898\n",
      "run 67 done with score 40.0 and running mean 14.435061773712329\n",
      "run 68 done with score 25.0 and running mean 14.540711155975206\n",
      "run 69 done with score 46.0 and running mean 14.855304044415455\n",
      "run 70 done with score 70.0 and running mean 15.4067510039713\n",
      "run 71 done with score 36.0 and running mean 15.612683493931586\n",
      "run 72 done with score 36.0 and running mean 15.816556658992269\n",
      "run 73 done with score 27.0 and running mean 15.928391092402347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2e19ccbf0c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8a0b384e5323>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# ÌòÑÏû¨ stateÏóêÏÑú Ìï† action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0maction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8a0b384e5323>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# state inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtemp_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_cast_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1755\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_defaulted_to_floatx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_about_input_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m           \u001b[0;31m# Inputs may be TensorSpecs when this function is called from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    689\u001b[0m   \u001b[0mbase_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   if isinstance(x,\n\u001b[0;32m--> 691\u001b[0;31m                 (ops.Tensor, _resource_variable_type)) and base_type == x.dtype:\n\u001b[0m\u001b[1;32m    692\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    259\u001b[0m                                other.base_dtype.as_datatype_enum)\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;34m\"\"\"Returns True iff this DType refers to the same type as `other`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "storage = Storage()\n",
    "agent = Brain(model, storage)\n",
    "model.summary()\n",
    "agent.train(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5288473+0.47115272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999993"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5144196+0.48558033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
