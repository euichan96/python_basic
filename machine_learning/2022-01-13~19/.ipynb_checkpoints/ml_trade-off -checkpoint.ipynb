{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "517fd4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  version -  1.20.3\n",
      "pandas version -  1.3.4\n",
      "sklearn version -  0.24.2\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "print('numpy  version - ' , np.__version__) \n",
    "print('pandas version - ' , pd.__version__) \n",
    "\n",
    "from   io import StringIO\n",
    "import missingno as msno\n",
    "# ml\n",
    "import sklearn\n",
    "from   sklearn.datasets import load_iris, load_breast_cancer\n",
    "\n",
    "print('sklearn version - ' , sklearn.__version__)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold , StratifiedKFold , cross_val_score, cross_validate, GridSearchCV \n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier         \n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics         import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, make_scorer, precision_recall_curve\n",
    "from sklearn.impute          import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing   import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0834a03",
   "metadata": {},
   "source": [
    "#### 분류모델의 성능평가\n",
    "- 정확도 : 실 데이터와 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "- 문제점? - 이진분류의 경우 모델의 성능을 왜곡할 수 있다.\n",
    "- 왜 : 데이터의 불균형\n",
    "- 해결책 : F1 Score(Percision , Reacall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081e3a1",
   "metadata": {},
   "source": [
    "#### 분류모델 성능평가를 위한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4fe3c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP(target = 1 , predict = 1)\n",
      "TN(target = 0 , predict = 0)\n",
      "FN(target = 1 , predict = 0) -> type 2 error\n",
      "FP(target = 0 , predict = 1) -> type 1 error\n",
      "\n",
      "\n",
      "TP(target = 1 , predict = 1)  3\n",
      "TN(target = 0 , predict = 0)  0\n",
      "FN(target = 1 , predict = 0) -> type 2 error  4\n",
      "FP(target = 0 , predict = 1) -> type 1 error  3\n"
     ]
    }
   ],
   "source": [
    "print('TP(target = 1 , predict = 1)')\n",
    "print('TN(target = 0 , predict = 0)')\n",
    "print('FN(target = 1 , predict = 0) -> type 2 error')\n",
    "print('FP(target = 0 , predict = 1) -> type 1 error')\n",
    "\n",
    "target     = [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "prediction = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "tp = tn = fn = fp = 0 \n",
    "for idx in range(len(target)) :\n",
    "    # TP\n",
    "    if target[idx] == 1 and prediction[idx] == 1 :\n",
    "        tp += 1\n",
    "    if target[idx] == 0 and prediction[idx] == 0 :\n",
    "        tn += 1\n",
    "    if target[idx] == 1 and prediction[idx] == 0 :\n",
    "        fn += 1\n",
    "    if target[idx] == 0 and prediction[idx] == 1 :\n",
    "        fp += 1\n",
    "print()\n",
    "print()\n",
    "print('TP(target = 1 , predict = 1) ' , tp)\n",
    "print('TN(target = 0 , predict = 0) ' , tn)\n",
    "print('FN(target = 1 , predict = 0) -> type 2 error ' , fn)\n",
    "print('FP(target = 0 , predict = 1) -> type 1 error ' , fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "24ed1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  -  0.3\n",
      "recall    -  0.42857142857142855\n",
      "precision -  0.5\n",
      "f1 score  -  0.4615384615384615\n",
      "\n",
      "confusion_matrix - \n",
      " [[0 3]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy  - ' , accuracy_score(target, prediction))\n",
    "print('recall    - ' , recall_score(target, prediction))\n",
    "print('precision - ' , precision_score(target, prediction))\n",
    "print('f1 score  - ' , f1_score(target, prediction))\n",
    "print()\n",
    "print('confusion_matrix - \\n' , confusion_matrix(target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4783cf",
   "metadata": {},
   "source": [
    "- 정밀도(Percision) : TP / (FP + TP)\n",
    "- 상대적으로 정밀도가 더 중요한 지표인 경우의 모델? - 스팸메일\n",
    "- 재현율(Recall) : TP / (FN + TP) \n",
    "- 상대적으로 재현율 더 중요한 지표인 경우의 모델? - 의학(암진단) , 금융(사기판별\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f463c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 로드\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"1. 데이터 로드\")\n",
    "print()\n",
    "titanic_frm = pd.read_csv(\"data/titanic_train.csv\")\n",
    "titanic_frm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2fbcf8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_frm['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2bc83c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. target , feature로 데이터 분리\n",
      "target  type -  <class 'pandas.core.series.Series'>\n",
      "feature type -  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print('2. target , feature로 데이터 분리')\n",
    "\n",
    "titanic_target  =  titanic_frm['Survived']\n",
    "titanic_feature =  titanic_frm.drop(['Survived'] , axis = 1) \n",
    "\n",
    "print('target  type - ' , type(titanic_target))\n",
    "print('feature type - ' , type(titanic_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1e004173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f2cd8e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 전처리 요구사항 - \n",
      "불필요한 피처 제거 - PassengerId, Name, Ticket\n",
      "결측값 처리        - Age는 평균, Cabin는 N, Embarked는 N\n",
      "cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!\n",
      "레이블 인코딩      - Sex, Cabin, Embarked\n"
     ]
    }
   ],
   "source": [
    "print('3. 전처리 요구사항 - ')\n",
    "print('불필요한 피처 제거 - PassengerId, Name, Ticket')\n",
    "print('결측값 처리        - Age는 평균, Cabin는 N, Embarked는 N')\n",
    "print('cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!')\n",
    "print('레이블 인코딩      - Sex, Cabin, Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4461e713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불필요한 피처 제거 - PassengerId, Name, Ticket\n"
     ]
    }
   ],
   "source": [
    "print('불필요한 피처 제거 - PassengerId, Name, Ticket')\n",
    "def drop_feature(frm):\n",
    "    frm.drop(['PassengerId', 'Name', 'Ticket'] , axis = 1, inplace=True) \n",
    "    return frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "63dbd9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         3    male  22.0      1      0   7.2500   NaN        S\n",
       "1         1  female  38.0      1      0  71.2833   C85        C\n",
       "2         3  female  26.0      0      0   7.9250   NaN        S\n",
       "3         1  female  35.0      1      0  53.1000  C123        S\n",
       "4         3    male  35.0      0      0   8.0500   NaN        S\n",
       "..      ...     ...   ...    ...    ...      ...   ...      ...\n",
       "886       2    male  27.0      0      0  13.0000   NaN        S\n",
       "887       1  female  19.0      0      0  30.0000   B42        S\n",
       "888       3  female   NaN      1      2  23.4500   NaN        S\n",
       "889       1    male  26.0      0      0  30.0000  C148        C\n",
       "890       3    male  32.0      0      0   7.7500   NaN        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_subset = drop_feature(titanic_feature)\n",
    "feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "69fbf531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 처리        - Age는 평균, Cabin는 N, Embarked는 N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('결측값 처리        - Age는 평균, Cabin는 N, Embarked는 N')\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "titanic_feature['Age'] = imputer.fit_transform(titanic_feature[['Age']])\n",
    "\n",
    "titanic_feature[['Cabin', 'Embarked']] = titanic_feature[['Cabin', 'Embarked']].fillna(\"N\")\n",
    "msno.matrix(titanic_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "542e8ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!\n",
      "레이블 인코딩      - Sex, Cabin, Embarked\n"
     ]
    }
   ],
   "source": [
    "print('cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!')\n",
    "print('레이블 인코딩      - Sex, Cabin, Embarked')\n",
    "\n",
    "def label_encoder(frm):\n",
    "    frm['Cabin'] = frm['Cabin'].str[:1]\n",
    "    features = ['Sex', 'Cabin', 'Embarked']\n",
    "    for feature in features :\n",
    "        encoder = LabelEncoder()\n",
    "        frm[feature] = encoder.fit_transform(frm[feature])\n",
    "    return frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ec414082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500      7         3\n",
       "1         1    0  38.000000      1      0  71.2833      2         0\n",
       "2         3    0  26.000000      0      0   7.9250      7         3\n",
       "3         1    0  35.000000      1      0  53.1000      2         3\n",
       "4         3    1  35.000000      0      0   8.0500      7         3\n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000      7         3\n",
       "887       1    0  19.000000      0      0  30.0000      1         3\n",
       "888       3    0  29.699118      1      2  23.4500      7         3\n",
       "889       1    1  26.000000      0      0  30.0000      2         0\n",
       "890       3    1  32.000000      0      0   7.7500      7         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_subset = label_encoder(titanic_feature)\n",
    "feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dc655ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('레이블 인코딩      - Sex')\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(titanic_feature.Sex)\n",
    "#print(encoder.classes_)\n",
    "#titanic_feature.Sex = encoder.transform(titanic_feature.Sex)\n",
    "#print(titanic_feature.Sex.head())\n",
    "\n",
    "#print('레이블 인코딩      - Cabin')\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(titanic_feature.Cabin.str[:1])\n",
    "#print(encoder.classes_)\n",
    "#titanic_feature.Cabin = encoder.transform(titanic_feature.Cabin.str[:1])\n",
    "#print(titanic_feature.Cabin.head())\n",
    "\n",
    "#print('레이블 인코딩      - Embarked')\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(titanic_feature.Embarked)\n",
    "#print(encoder.classes_)\n",
    "#titanic_feature.Embarked = encoder.transform(titanic_feature.Embarked)\n",
    "#print(titanic_feature.Embarked.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d2294e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500      7         3\n",
       "1         1    0  38.000000      1      0  71.2833      2         0\n",
       "2         3    0  26.000000      0      0   7.9250      7         3\n",
       "3         1    0  35.000000      1      0  53.1000      2         3\n",
       "4         3    1  35.000000      0      0   8.0500      7         3\n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000      7         3\n",
       "887       1    0  19.000000      0      0  30.0000      1         3\n",
       "888       3    0  29.699118      1      2  23.4500      7         3\n",
       "889       1    1  26.000000      0      0  30.0000      2         0\n",
       "890       3    1  32.000000      0      0   7.7500      7         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "348d8712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습과 테스트 분리 - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('학습과 테스트 분리 - ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a28fb74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 01. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('step 01. \\n')\n",
    "x_train, x_test ,y_train, y_test = train_test_split(feature_subset,\n",
    "                                                    titanic_target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "21f1546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 8), (179, 8), (712,), (179,))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape ,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b3b6b8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "lr_y_pred = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c56bc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(x_train, y_train)\n",
    "dt_y_pred = dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ea11942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_eval(target, prediction):\n",
    "    print('accuracy  - ' , accuracy_score(target, prediction))\n",
    "    print('recall    - ' , recall_score(target, prediction))\n",
    "    print('precision - ' , precision_score(target, prediction))\n",
    "    print('f1 score  - ' , f1_score(target, prediction))\n",
    "    print()\n",
    "    print('confusion_matrix - \\n' , confusion_matrix(target, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e603ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - \n",
      "\n",
      "accuracy  -  0.8044692737430168\n",
      "recall    -  0.72\n",
      "precision -  0.7941176470588235\n",
      "f1 score  -  0.7552447552447551\n",
      "\n",
      "confusion_matrix - \n",
      " [[90 14]\n",
      " [21 54]]\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression - \\n')\n",
    "metrics_eval(y_test, lr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "632c9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - \n",
      "\n",
      "accuracy  -  0.7877094972067039\n",
      "recall    -  0.76\n",
      "precision -  0.7402597402597403\n",
      "f1 score  -  0.75\n",
      "\n",
      "confusion_matrix - \n",
      " [[84 20]\n",
      " [18 57]]\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier - \\n')\n",
    "metrics_eval(y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b60426b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1'])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('교차검증 - ')\n",
    "fold = KFold(n_splits = 20)\n",
    "scoring = {\n",
    "    'accuracy'  : make_scorer(accuracy_score),\n",
    "    'precision' : make_scorer(precision_score),\n",
    "    'recall'    : make_scorer(recall_score),\n",
    "    'f1'        : make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "result = cross_validate(lr_model, x_train, y_train,\n",
    "                       cv = fold,\n",
    "                       scoring = scoring )\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0806fd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7895634920634922"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6701f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b7c756",
   "metadata": {},
   "source": [
    "### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c53a83d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3641fb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유방암 관련 데이터 - 정화도, 재현율(실제 P를 N예측하면 안되기 때문에\n",
      "재현율은 실제 양성을 양성으로 예측한 비율이 높아야 성능이 좋은 모델\n"
     ]
    }
   ],
   "source": [
    "print('유방암 관련 데이터 - 정화도, 재현율(실제 P를 N예측하면 안되기 때문에')\n",
    "print('재현율은 실제 양성을 양성으로 예측한 비율이 높아야 성능이 좋은 모델')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ee61a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 프레임 만들기(feature, target) 포함\n",
      "2. target에 대한 균형 여부 확인\n",
      "3. 데이터 세트 분리\n",
      "4. RandomForestClassifier\n",
      "5. 평가지표 확인\n"
     ]
    }
   ],
   "source": [
    "print(\"1. 프레임 만들기(feature, target) 포함\")\n",
    "print(\"2. target에 대한 균형 여부 확인\")\n",
    "print(\"3. 데이터 세트 분리\")\n",
    "print(\"4. RandomForestClassifier\")\n",
    "print(\"5. 평가지표 확인\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8c33e181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 프레임 만들기(feature, target) 포함\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"1. 프레임 만들기(feature, target) 포함\")\n",
    "\n",
    "cancer_DF = pd.DataFrame(data = cancer.data,\n",
    "                       columns = cancer.feature_names)\n",
    "cancer_DF['target'] = cancer.target\n",
    "cancer_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ccc8ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. target에 대한 균형 여부 확인\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2. target에 대한 균형 여부 확인\")\n",
    "\n",
    "cancer_DF['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ce50d24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 데이터 세트 분리\n",
      "<class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"3. 데이터 세트 분리\")\n",
    "\n",
    "cancer_target  = cancer_DF['target']\n",
    "cancer_features = cancer_DF.drop(['target'], axis=1)\n",
    "print(type(cancer_target), type(cancer_features))\n",
    "\n",
    "\n",
    "x_train, x_test ,y_train, y_test = train_test_split(cancer.data,\n",
    "                                                    cancer.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=100)\n",
    "x_train.shape, x_test.shape ,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4ee76539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "print(\"4. RandomForestClassifier\")\n",
    "\n",
    "cancer_lr_model = RandomForestClassifier() #의사결정트리\n",
    "cancer_lr_model.fit(x_train, y_train)\n",
    "cancer_lr_y_pred = cancer_lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "de340699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. 평가지표 확인\n",
      "RandomForestClassifier - \n",
      "\n",
      "accuracy  -  0.9736842105263158\n",
      "recall    -  0.9846153846153847\n",
      "precision -  0.9696969696969697\n",
      "f1 score  -  0.9770992366412214\n",
      "\n",
      "confusion_matrix - \n",
      " [[47  2]\n",
      " [ 1 64]]\n"
     ]
    }
   ],
   "source": [
    "print(\"5. 평가지표 확인\")\n",
    "print('RandomForestClassifier - \\n')\n",
    "metrics_eval(y_test, cancer_lr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "09360dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1'])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('교차검증 - ')\n",
    "fold = KFold(n_splits = 20)\n",
    "scoring = {\n",
    "    'accuracy'  : make_scorer(accuracy_score),\n",
    "    'precision' : make_scorer(precision_score),\n",
    "    'recall'    : make_scorer(recall_score),\n",
    "    'f1'        : make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "result = cross_validate(cancer_lr_model, x_train, y_train,\n",
    "                       cv = fold,\n",
    "                       scoring = scoring )\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "99ed5303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9539525691699605"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "89437c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재현율을 높이기위한 방법으로 - GridSearchCV를 이용한 파라미터 튜닝!!\n",
      "n_estimators - tree 갯수를 의미\n",
      "max_features - 최대 선택할 피처의 수를 의미\n",
      "max_depth    - 최대 선택할 트리의 깊이를 의미\n"
     ]
    }
   ],
   "source": [
    "print(\"재현율을 높이기위한 방법으로 - GridSearchCV를 이용한 파라미터 튜닝!!\")\n",
    "print('n_estimators - tree 갯수를 의미')\n",
    "print('max_features - 최대 선택할 피처의 수를 의미')\n",
    "print('max_depth    - 최대 선택할 트리의 깊이를 의미')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "9ed7fd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [4, 6, 8], 'max_features': [6, 8, 15, 20],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {\n",
    "    'n_estimators' : [50, 100, 150, 200],\n",
    "    'max_features' : [6, 8, 15 ,20],\n",
    "    'max_depth'    : [4, 6, 8]\n",
    "}\n",
    "\n",
    "grid_search_model = GridSearchCV(cancer_lr_model,\n",
    "                 param_grid=param,\n",
    "                 cv = 20,\n",
    "                 refit=True,\n",
    "                 scoring='recall'\n",
    "                )\n",
    "grid_search_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "139d3984",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.05065821, 0.10012552, 0.1521408 , 0.19960146, 0.0563466 ,\n",
       "        0.11288525, 0.16789224, 0.22204808, 0.07538626, 0.14923127,\n",
       "        0.22123057, 0.29363695, 0.08605987, 0.17367364, 0.25649096,\n",
       "        0.34241364, 0.05330335, 0.10654773, 0.15944705, 0.21244731,\n",
       "        0.05986886, 0.11877635, 0.17496561, 0.23605301, 0.0796842 ,\n",
       "        0.15781412, 0.2379873 , 0.31613666, 0.09380074, 0.19170082,\n",
       "        0.27902663, 0.37367871, 0.05360541, 0.1071928 , 0.1608197 ,\n",
       "        0.21152282, 0.06151147, 0.11725421, 0.17816255, 0.23642917,\n",
       "        0.07989007, 0.15975689, 0.23806571, 0.32271204, 0.09537048,\n",
       "        0.18936561, 0.2813309 , 0.37444345]),\n",
       " 'std_fit_time': array([0.00299678, 0.00346011, 0.00612697, 0.00727619, 0.00186174,\n",
       "        0.00413941, 0.00431767, 0.00577059, 0.00387082, 0.00478366,\n",
       "        0.00575887, 0.00710352, 0.00319857, 0.00504388, 0.00731748,\n",
       "        0.00564813, 0.00257875, 0.00468648, 0.0043437 , 0.00606245,\n",
       "        0.00336182, 0.00488587, 0.00456562, 0.00650233, 0.00306354,\n",
       "        0.00395838, 0.00472647, 0.00695569, 0.00380165, 0.00986552,\n",
       "        0.00756145, 0.01093587, 0.00314512, 0.00326116, 0.00483623,\n",
       "        0.00594942, 0.00336626, 0.00312958, 0.00728696, 0.00620736,\n",
       "        0.00416365, 0.00599161, 0.00505972, 0.02221757, 0.00357227,\n",
       "        0.00644366, 0.00489242, 0.00863515]),\n",
       " 'mean_score_time': array([0.00326473, 0.00544841, 0.00725315, 0.01006387, 0.00331566,\n",
       "        0.00560671, 0.00800668, 0.00979359, 0.00284252, 0.00540884,\n",
       "        0.00734043, 0.00990012, 0.00296842, 0.00557314, 0.00748864,\n",
       "        0.00989752, 0.00317762, 0.00511738, 0.00772792, 0.01061294,\n",
       "        0.00300716, 0.00542661, 0.00817784, 0.00988896, 0.00310385,\n",
       "        0.00550222, 0.00784426, 0.00974486, 0.00306959, 0.00531979,\n",
       "        0.00777091, 0.00969008, 0.00285962, 0.00560685, 0.00742606,\n",
       "        0.00937971, 0.00294868, 0.0053319 , 0.00805205, 0.00965889,\n",
       "        0.00307345, 0.00567477, 0.00786072, 0.01019702, 0.00299773,\n",
       "        0.00546842, 0.00751346, 0.00993859]),\n",
       " 'std_score_time': array([0.00054866, 0.00128406, 0.00089466, 0.00117103, 0.00077387,\n",
       "        0.00096156, 0.00140708, 0.00112604, 0.00043393, 0.00089588,\n",
       "        0.00089626, 0.00101196, 0.00061797, 0.00082659, 0.00083927,\n",
       "        0.00122863, 0.00065856, 0.00068298, 0.00122435, 0.0020775 ,\n",
       "        0.00046519, 0.00117765, 0.00123441, 0.0014767 , 0.00053181,\n",
       "        0.00116237, 0.0013205 , 0.00141749, 0.00068227, 0.00092104,\n",
       "        0.00091123, 0.00111855, 0.0005911 , 0.00120516, 0.00059806,\n",
       "        0.00085311, 0.0004639 , 0.00087132, 0.001314  , 0.0006848 ,\n",
       "        0.00069896, 0.00109996, 0.00093161, 0.00140269, 0.00069045,\n",
       "        0.00084655, 0.00086627, 0.00076817]),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20,\n",
       "                    6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20,\n",
       "                    6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
       "                    200, 50, 100, 150, 200, 50, 100, 150, 200, 50, 100,\n",
       "                    150, 200, 50, 100, 150, 200, 50, 100, 150, 200, 50,\n",
       "                    100, 150, 200, 50, 100, 150, 200, 50, 100, 150, 200,\n",
       "                    50, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 4, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 200}],\n",
       " 'split0_test_score': array([0.93333333, 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        1.        , 1.        , 0.93333333, 1.        , 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 1.        , 1.        , 0.93333333, 0.93333333,\n",
       "        1.        , 1.        , 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 1.        , 1.        , 1.        , 0.93333333,\n",
       "        0.93333333, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.93333333, 1.        , 0.93333333]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.93333333,\n",
       "        1.        , 1.        , 1.        , 0.93333333, 1.        ,\n",
       "        0.93333333, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333]),\n",
       " 'split3_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.93333333, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split5_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split6_test_score': array([0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333]),\n",
       " 'split7_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split8_test_score': array([0.93333333, 0.93333333, 0.86666667, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.86666667, 0.93333333, 0.93333333,\n",
       "        1.        , 0.93333333, 0.93333333, 0.93333333, 1.        ,\n",
       "        1.        , 0.86666667, 0.93333333, 0.86666667, 0.86666667,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 1.        ,\n",
       "        1.        , 0.93333333, 0.93333333, 1.        , 1.        ,\n",
       "        1.        , 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.86666667, 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.93333333,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split9_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split10_test_score': array([0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333]),\n",
       " 'split11_test_score': array([0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.86666667,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.86666667, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.86666667]),\n",
       " 'split12_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split13_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split14_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.92857143, 0.92857143,\n",
       "        1.        , 1.        , 0.92857143, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split15_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.92857143, 0.85714286,\n",
       "        1.        , 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 1.        , 0.92857143, 0.92857143,\n",
       "        1.        , 0.92857143, 0.92857143]),\n",
       " 'split16_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split17_test_score': array([1.        , 1.        , 1.        , 0.92857143, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 0.92857143, 1.        , 1.        , 0.92857143,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.92857143, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split18_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92857143, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.92857143, 0.92857143,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split19_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.9797619 , 0.9797619 , 0.9797619 , 0.97619048, 0.9797619 ,\n",
       "        0.97619048, 0.9797619 , 0.97285714, 0.97261905, 0.96904762,\n",
       "        0.98285714, 0.97238095, 0.97261905, 0.97595238, 0.97595238,\n",
       "        0.97238095, 0.97642857, 0.9797619 , 0.97642857, 0.97642857,\n",
       "        0.97261905, 0.97619048, 0.97619048, 0.97619048, 0.96571429,\n",
       "        0.97595238, 0.97595238, 0.97952381, 0.96214286, 0.96880952,\n",
       "        0.97261905, 0.97952381, 0.97261905, 0.97261905, 0.9797619 ,\n",
       "        0.97642857, 0.98309524, 0.98642857, 0.98309524, 0.9797619 ,\n",
       "        0.97595238, 0.98285714, 0.97952381, 0.97595238, 0.96904762,\n",
       "        0.97619048, 0.97595238, 0.96928571]),\n",
       " 'std_test_score': array([0.03092948, 0.03092948, 0.03743096, 0.03247186, 0.03092948,\n",
       "        0.03247186, 0.03092948, 0.03938588, 0.03356636, 0.04103259,\n",
       "        0.0297152 , 0.03385979, 0.03356636, 0.03280102, 0.03280102,\n",
       "        0.03385979, 0.03843524, 0.03092948, 0.03843524, 0.03843524,\n",
       "        0.03356636, 0.03247186, 0.03247186, 0.03247186, 0.04028245,\n",
       "        0.03280102, 0.03280102, 0.03130205, 0.04025077, 0.03451888,\n",
       "        0.03356636, 0.03130205, 0.03356636, 0.03356636, 0.03092948,\n",
       "        0.03843524, 0.02929539, 0.02715852, 0.02929539, 0.03092948,\n",
       "        0.03280102, 0.0297152 , 0.03130205, 0.03280102, 0.03425594,\n",
       "        0.03247186, 0.03280102, 0.03999646]),\n",
       " 'rank_test_score': array([ 6,  6,  6, 25,  6, 21,  6, 34, 35, 44,  4, 42, 35, 27, 27, 41, 17,\n",
       "         6, 17, 17, 35, 25, 21, 21, 47, 27, 27, 14, 48, 46, 35, 14, 35, 35,\n",
       "         6, 17,  2,  1,  2,  6, 27,  4, 14, 27, 44, 21, 27, 43])}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "731d8a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 8, 'n_estimators': 100}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d86b3fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864285714285714"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2dd21af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_estimator = grid_search_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "374bef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  -  0.9736842105263158\n",
      "recall    -  0.9846153846153847\n",
      "precision -  0.9696969696969697\n",
      "f1 score  -  0.9770992366412214\n",
      "\n",
      "confusion_matrix - \n",
      " [[47  2]\n",
      " [ 1 64]]\n"
     ]
    }
   ],
   "source": [
    "beat_y_pred = rf_estimator.predict(x_test)\n",
    "metrics_eval(y_test, beat_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f36d3c",
   "metadata": {},
   "source": [
    "## 정밀도와 재현율을 임의로 조절하는 모델을 생성해야하는 경우\n",
    "- 분류 임계값이 낮을수록 Positive를 예측할 확률이 높아져 재현율이 증가\n",
    "- predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "19b764e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "    [-1, -1, 2],\n",
    "    [2, 0, 0],\n",
    "    [0, 1.1, 1.2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "44e16a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "holder = Binarizer(threshold=1.1)\n",
    "print(holder.fit_transform(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c38a5078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500      7         3\n",
       "1         1    0  38.000000      1      0  71.2833      2         0\n",
       "2         3    0  26.000000      0      0   7.9250      7         3\n",
       "3         1    0  35.000000      1      0  53.1000      2         3\n",
       "4         3    1  35.000000      0      0   8.0500      7         3\n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000      7         3\n",
       "887       1    0  19.000000      0      0  30.0000      1         3\n",
       "888       3    0  29.699118      1      2  23.4500      7         3\n",
       "889       1    1  26.000000      0      0  30.0000      2         0\n",
       "890       3    1  32.000000      0      0   7.7500      7         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "28189bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습과 테스트 분리 - \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((712, 8), (179, 8), (712,), (179,))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('학습과 테스트 분리 - \\n')\\\n",
    "\n",
    "x_train, x_test ,y_train, y_test = train_test_split(feature_subset,\n",
    "                                                    titanic_target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=100)\n",
    "x_train.shape, x_test.shape ,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "668ff526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred = logistic_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c1166023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률 예측 값 - predict_proba()\n",
      "type  -  <class 'numpy.ndarray'>\n",
      "shape -  (179, 2)\n"
     ]
    }
   ],
   "source": [
    "print('확률 예측 값 - predict_proba()')\n",
    "predict_proba_result = logistic_model.predict_proba(x_test)\n",
    "print('type  - ', type(predict_proba_result))\n",
    "print('shape - ', predict_proba_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "99ee3139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16508234, 0.83491766],\n",
       "       [0.26669725, 0.73330275],\n",
       "       [0.89524357, 0.10475643]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_result[0 : 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ca7a3145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b41bb9ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16508234, 0.83491766, 1.        ],\n",
       "       [0.26669725, 0.73330275, 1.        ],\n",
       "       [0.89524357, 0.10475643, 0.        ],\n",
       "       [0.41408318, 0.58591682, 1.        ],\n",
       "       [0.86456379, 0.13543621, 0.        ],\n",
       "       [0.24027054, 0.75972946, 1.        ],\n",
       "       [0.89838722, 0.10161278, 0.        ],\n",
       "       [0.79072248, 0.20927752, 0.        ],\n",
       "       [0.05768705, 0.94231295, 1.        ],\n",
       "       [0.6357547 , 0.3642453 , 0.        ]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_concat = np.concatenate([predict_proba_result , y_pred.reshape(-1,1)], axis=1)\n",
    "predict_proba_concat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "682d8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_th = 0.3\n",
    "predict_proba_positive = predict_proba_result[: , 1].reshape(-1,1)\n",
    "user_pred = Binarizer(threshold=user_th) \\\n",
    "                    .fit_transform(predict_proba_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "93d28d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default - \n",
      "\n",
      "accuracy  -  0.8044692737430168\n",
      "recall    -  0.72\n",
      "precision -  0.7941176470588235\n",
      "f1 score  -  0.7552447552447551\n",
      "\n",
      "confusion_matrix - \n",
      " [[90 14]\n",
      " [21 54]]\n",
      "user th - 0.3\n",
      "\n",
      "accuracy  -  0.7932960893854749\n",
      "recall    -  0.7733333333333333\n",
      "precision -  0.7435897435897436\n",
      "f1 score  -  0.7581699346405228\n",
      "\n",
      "confusion_matrix - \n",
      " [[84 20]\n",
      " [17 58]]\n"
     ]
    }
   ],
   "source": [
    "print('default - \\n')\n",
    "metrics_eval(y_test, y_pred)\n",
    "\n",
    "print('user th - 0.3\\n')\n",
    "metrics_eval(y_test, user_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa27be38",
   "metadata": {},
   "source": [
    "## trade-off 시각화\n",
    "- precision_recall_curve(실제값, 예측 확률 값) : 임계값 변화에 따른 평가지표를 반환\n",
    "- 반환값 : 정밀도, 재현율, 임계 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3393417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9fe1fa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type - <class 'numpy.ndarray'>\n",
      "recall     type - <class 'numpy.ndarray'>\n",
      "th         type - <class 'numpy.ndarray'>\n",
      "prediction shape - (149,)\n",
      "recall     shape - (149,)\n",
      "th         shape - (148,)\n"
     ]
    }
   ],
   "source": [
    "predict_proba_positive = predict_proba_result[: , 1]\n",
    "prediction, recall, th = precision_recall_curve(y_test, predict_proba_positive)\n",
    "print('prediction type -',type(prediction))\n",
    "print('recall     type -',type(recall))\n",
    "print('th         type -',type(prediction))\n",
    "print('prediction shape -',prediction.shape)\n",
    "print('recall     shape -',recall.shape)\n",
    "print('th         shape -',th.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "7f152833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46583851, 0.46540881, 0.46835443, 0.47133758, 0.47435897,\n",
       "       0.47096774, 0.48026316, 0.48666667, 0.48993289, 0.49324324,\n",
       "       0.48979592, 0.49315068, 0.49305556, 0.4965035 , 0.5       ,\n",
       "       0.5035461 , 0.50714286, 0.50359712, 0.50724638, 0.50364964,\n",
       "       0.50735294, 0.5112782 , 0.51515152, 0.51908397, 0.52307692,\n",
       "       0.52713178, 0.53125   , 0.53543307, 0.53968254, 0.544     ,\n",
       "       0.5483871 , 0.55284553, 0.55737705, 0.56198347, 0.56666667,\n",
       "       0.56302521, 0.56779661, 0.57264957, 0.56896552, 0.57391304,\n",
       "       0.57894737, 0.5840708 , 0.58035714, 0.58558559, 0.59633028,\n",
       "       0.60185185, 0.60747664, 0.61320755, 0.61904762, 0.625     ,\n",
       "       0.63106796, 0.6372549 , 0.63366337, 0.64      , 0.64646465,\n",
       "       0.64285714, 0.63917526, 0.64583333, 0.64210526, 0.64893617,\n",
       "       0.67032967, 0.67777778, 0.6741573 , 0.68181818, 0.68965517,\n",
       "       0.69767442, 0.70588235, 0.71428571, 0.72289157, 0.73170732,\n",
       "       0.74074074, 0.7375    , 0.73417722, 0.74358974, 0.74025974,\n",
       "       0.75      , 0.76      , 0.75675676, 0.76712329, 0.77777778,\n",
       "       0.77464789, 0.78571429, 0.7826087 , 0.79411765, 0.79104478,\n",
       "       0.78787879, 0.78461538, 0.796875  , 0.80952381, 0.82258065,\n",
       "       0.83606557, 0.83333333, 0.83050847, 0.82758621, 0.83928571,\n",
       "       0.83018868, 0.84615385, 0.84313725, 0.84      , 0.83673469,\n",
       "       0.83333333, 0.85106383, 0.84782609, 0.84444444, 0.84090909,\n",
       "       0.8372093 , 0.85714286, 0.85365854, 0.85      , 0.84615385,\n",
       "       0.84210526, 0.83783784, 0.86111111, 0.85714286, 0.88235294,\n",
       "       0.87878788, 0.90625   , 0.90322581, 0.9       , 0.93103448,\n",
       "       0.92857143, 0.92592593, 0.96153846, 0.96      , 0.95833333,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "91f58679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ValueError: x and y must have same first dimension, but have shapes (148,) and (149,)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(th, prediction[0 : th.shape[0]], linestyle=\"--\", label='prediction')\n",
    "plt.plot(th, recall[0 : th.shape[0]]    , linestyle=\"-\", label='recall')\n",
    "\n",
    "plt.xlabel('threshold ratio')\n",
    "plt.ylabel('prediction and recall value')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1539cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78f00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
